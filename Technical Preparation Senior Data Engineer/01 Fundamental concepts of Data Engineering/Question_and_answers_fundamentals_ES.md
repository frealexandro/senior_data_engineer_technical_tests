# üìò PREGUNTAS_Y_RESPUESTAS_FUNDAMENTOS_GENERAL

---

## üêç 0. ¬øQu√© es Python?

Python es un lenguaje tipado, pero usa **tipado din√°mico**, lo que significa que no tienes que declarar los tipos de variables ‚Äî Python los determina en tiempo de ejecuci√≥n.

---

### üîê 0.1 Existen objetos inmutables y mutables ‚Äî ¬øqu√© son?

En Python, algunos objetos son mutables y otros son inmutables.

| Tipo | ¬øSe puede cambiar? | Ejemplos |
|------|-------------------|----------|
| üîí **Inmutable** | ‚ùå No | `int`, `float`, `string`, `tuple`, `bool` |
| üîì **Mutable** | ‚úÖ S√≠ | `list`, `dict`, `set` |

**Diferencia simple:**
- **Inmutable** = no puedes modificar el objeto en s√≠ (si lo "cambias", Python crea un nuevo objeto)
- **Mutable** = puedes modificar el objeto en su lugar (no se crea un nuevo objeto)

---

### ‚öôÔ∏è 0.2 ¬øQu√© es una funci√≥n?

Una funci√≥n es un bloque de c√≥digo reutilizable que recibe una entrada, realiza alguna l√≥gica y devuelve una salida.

---

## üóÑÔ∏è 1. ¬øQu√© es SQL (Structured Query Language)?

SQL (Structured Query Language) es un lenguaje usado para almacenar, recuperar y gestionar datos en bases de datos relacionales. Te permite consultar datos, actualizarlos y organizarlos usando tablas.

---

### üìã 1.2 ¬øCu√°l es la diferencia entre DDL y DML?

| Categor√≠a | Nombre Completo | Prop√≥sito | Comandos |
|-----------|-----------------|-----------|----------|
| üèóÔ∏è **DDL** | Data Definition Language | Definir/cambiar estructura | `CREATE`, `ALTER`, `DROP`, `TRUNCATE` |
| üìù **DML** | Data Manipulation Language | Trabajar con datos | `SELECT`, `INSERT`, `UPDATE`, `DELETE` |

---

### üìä 1.3 ¬øQu√© es una agregaci√≥n?

Una agregaci√≥n (en SQL o ingenier√≠a de datos) es una operaci√≥n que combina m√∫ltiples filas en un solo resultado aplicando una funci√≥n.

| Funci√≥n | Descripci√≥n |
|---------|-------------|
| `SUM()` | Suma valores |
| `COUNT()` | Cuenta filas |
| `AVG()` | Promedio |
| `MAX()` / `MIN()` | Valor m√°s alto o m√°s bajo |

---

### üîß 1.4 Otros tipos de operaciones

| Operaci√≥n | Descripci√≥n | Palabras clave |
|-----------|-------------|----------------|
| üîç **Filtrado** | Selecciona solo las filas que quieres | `WHERE`, `HAVING` |
| üîó **Joins** | Combina datos de m√∫ltiples tablas | `INNER`, `LEFT`, `RIGHT`, `FULL` |
| üìä **Ordenamiento** | Ordena los resultados | `ORDER BY` |
| üì¶ **Agrupamiento** | Agrupa filas para agregaciones | `GROUP BY` |
| ü™ü **Window Functions** | C√°lculos sobre conjuntos de filas | `OVER()` |
| ‚ûï **Operaciones de Conjunto** | Combina resultados de queries | `UNION`, `INTERSECT`, `EXCEPT` |
| üîÑ **Subqueries** | Queries dentro de otros queries | `(SELECT ...)` |

```sql
SELECT *
FROM employees
WHERE salary > (SELECT AVG(salary) FROM employees);
```

---

## üåä 2. ¬øCu√°l es la diferencia entre Delta Lake y Data Lake?

| Caracter√≠stica | üåä Data Lake | üî∫ Delta Lake |
|----------------|--------------|---------------|
| **Definici√≥n** | Almacenamiento grande para todo tipo de datos | Data lake mejorado con confiabilidad |
| **Calidad de Datos** | ‚ùå Sin garant√≠as | ‚úÖ Aplicaci√≥n de esquema |
| **Transacciones ACID** | ‚ùå No | ‚úÖ S√≠ |
| **Time Travel** | ‚ùå No | ‚úÖ S√≠ (historial de versiones) |
| **Updates/Deletes** | ‚ùå Dif√≠cil | ‚úÖ F√°cil |

**Analog√≠a simple:**
- üè† **Data Lake** = Una gran bodega donde puedes poner cualquier cosa
- üè¢ **Delta Lake** = La misma bodega pero con organizaci√≥n, etiquetas, seguridad y seguimiento

---

## ‚ö° 3. ¬øQu√© es Spark?

Apache Spark es un framework r√°pido y de c√≥digo abierto usado para procesar grandes cantidades de datos a trav√©s de muchas m√°quinas.

| Capacidad | Descripci√≥n |
|-----------|-------------|
| üìä **Batch Processing** | Procesa grandes datasets |
| üåä **Streaming** | Procesamiento de datos en tiempo real |
| üóÉÔ∏è **SQL** | Consulta datos con Spark SQL |
| ü§ñ **ML** | Machine learning con MLlib |

**¬øPor qu√© es popular Spark?**

| Ventaja | Descripci√≥n |
|---------|-------------|
| üöÄ **Velocidad** | 100x m√°s r√°pido que Hadoop MapReduce (en memoria) |
| üêç **F√°cil de Usar** | Soporte para Python, SQL, Scala, Java |
| üìà **Escalable** | Desde laptop hasta miles de servidores |

> üí° **¬øPor qu√© Spark es m√°s r√°pido que MapReduce?**
> 
> - **Hadoop MapReduce** escribe resultados intermedios a HDFS (disco) despu√©s de cada etapa map y reduce. Esto lo hace m√°s lento pero muy tolerante a fallos.
> - **Apache Spark** almacena la mayor√≠a de los datos intermedios en memoria (RAM) usando RDDs, lo que lo hace mucho m√°s r√°pido que MapReduce.

---

## üì¶ 4. ¬øQu√© es un RDD?

Un **RDD** (Resilient Distributed Dataset) es la estructura de datos b√°sica en Apache Spark. Representa una colecci√≥n de datos tolerante a fallos dividida entre muchas m√°quinas.

| Propiedad | Descripci√≥n |
|-----------|-------------|
| üîí **Inmutable** | No puede cambiar una vez creado |
| üíæ **En Memoria** | Procesamiento r√°pido |
| üåê **Distribuido** | Dividido entre m√°quinas |
| üîÑ **Tolerante a Fallos** | Auto-recuperaci√≥n v√≠a lineage |

---

### ‚öñÔ∏è 4.1 ¬øCu√°l es la diferencia entre RDD y DataFrame?

| Aspecto | üì¶ RDD | üìä DataFrame |
|---------|--------|--------------|
| **Nivel** | Bajo nivel | Alto nivel |
| **Esquema** | ‚ùå Sin esquema | ‚úÖ Tiene esquema |
| **Optimizaci√≥n** | ‚ùå Manual | ‚úÖ Optimizador Catalyst |
| **Facilidad de Uso** | Complejo | F√°cil (similar a SQL) |
| **Rendimiento** | Bueno | Mejor (optimizado) |
| **Mejor Para** | Datos no estructurados | Datos estructurados |

---

### üîÑ 4.2 ¬øCu√°l es la diferencia entre Transformaciones y Acciones en Spark?

En Spark, las operaciones sobre RDDs/DataFrames se dividen en dos categor√≠as:

| Aspecto | üîÑ Transformaciones | ‚ñ∂Ô∏è Acciones |
|---------|---------------------|-------------|
| **Ejecuci√≥n** | Lazy (no se ejecutan inmediatamente) | Eager (dispara la ejecuci√≥n) |
| **Retorna** | Nuevo RDD/DataFrame | Resultado al driver o almacenamiento |
| **Ejemplos** | `map`, `filter`, `select`, `groupBy`, `join` | `collect`, `count`, `show`, `write`, `take` |
| **DAG** | Construye el plan de ejecuci√≥n | Ejecuta el DAG |

**üîÑ Transformaciones (Lazy):**
- Crean un nuevo RDD/DataFrame a partir de uno existente
- No se ejecutan hasta que se llama una acci√≥n
- Construyen el **DAG (Directed Acyclic Graph)** de operaciones

```python
# Estas son transformaciones - ¬°nada se ejecuta a√∫n!
df_filtered = df.filter(df["age"] > 25)
df_selected = df_filtered.select("name", "salary")
df_grouped = df_selected.groupBy("name").sum("salary")
```

**‚ñ∂Ô∏è Acciones (Eager):**
- Disparan la ejecuci√≥n de todas las transformaciones
- Devuelven resultados al driver o escriben al almacenamiento

```python
# Esta es una acci√≥n - ¬°AHORA todas las transformaciones se ejecutan!
df_grouped.show()        # Acci√≥n: muestra resultados
df_grouped.count()       # Acci√≥n: devuelve n√∫mero de filas
df_grouped.collect()     # Acci√≥n: devuelve todos los datos al driver
df_grouped.write.parquet("output/")  # Acci√≥n: escribe al almacenamiento
```

> üí° **¬øPor qu√© Evaluaci√≥n Lazy?**
> 
> Spark usa evaluaci√≥n lazy porque permite al **Catalyst Optimizer** analizar el DAG completo y optimizar el plan de ejecuci√≥n antes de ejecutar. Esto lleva a:
> - **Mejor rendimiento:** Combina m√∫ltiples operaciones en menos pasos
> - **Menor I/O:** Evita escrituras intermedias innecesarias
> - **Optimizaci√≥n:** Predicate pushdown, column pruning, reordenamiento de joins

| Tipo de Transformaci√≥n | Descripci√≥n | Ejemplos |
|------------------------|-------------|----------|
| **Narrow** | Cada partici√≥n depende de una partici√≥n padre | `map`, `filter`, `select` |
| **Wide** | Las particiones dependen de m√∫ltiples particiones padre (shuffle) | `groupBy`, `join`, `repartition` |

> üéØ **Tip de Entrevista:** "Entiendo que las transformaciones son lazy y construyen el DAG, mientras que las acciones disparan la ejecuci√≥n. Por esto puedo encadenar muchas transformaciones sin problemas de rendimiento - Spark optimiza todo el plan antes de ejecutar. Tambi√©n conozco la diferencia entre transformaciones narrow y wide, lo que me ayuda a entender cu√°ndo ocurren shuffles."

---

## üì® 5. ¬øQu√© es Apache Kafka?

Apache Kafka es una plataforma de streaming distribuida usada para mover datos entre sistemas en tiempo real.

| Componente | Descripci√≥n |
|------------|-------------|
| üì§ **Producer** | Env√≠a mensajes a Kafka |
| üìÅ **Topic** | Categor√≠a/stream de mensajes |
| üìä **Partition** | Subdivisi√≥n para paralelismo |
| üì• **Consumer** | Lee mensajes de Kafka |
| üë• **Consumer Group** | Equipo de consumers |
| üî¢ **Offset** | Rastreador de posici√≥n de mensaje |

**Usado para:**
- Pipelines de datos en tiempo real
- Sistemas event-driven
- Streaming de logs/m√©tricas
- Comunicaci√≥n de microservicios
- ETL streaming

---

### üîÑ 5.1 ¬øC√≥mo funciona Kafka?

**Flujo:** `Producer ‚Üí Topic/Partitions ‚Üí Consumer Group`

**Garant√≠as de Kafka:**

| Garant√≠a | Descripci√≥n |
|----------|-------------|
| üöÄ **Alto Throughput** | Millones de mensajes/segundo |
| üíæ **Durabilidad** | Mensajes almacenados en disco |
| üìà **Escalabilidad** | Escalado horizontal |
| üìä **Ordenamiento** | Garantizado dentro de partici√≥n |
| üîÑ **Tolerancia a Fallos** | Replicaci√≥n entre brokers |

---

### ‚öñÔ∏è 5.2 Kafka vs Pub/Sub Tradicional

| Caracter√≠stica | üì® Kafka | üì¢ Pub/Sub Tradicional (SNS/RabbitMQ) |
|----------------|----------|---------------------------------------|
| **Almacenamiento de Mensajes** | ‚úÖ Persistido (d√≠as/semanas) | ‚ùå Se pierde despu√©s de entrega |
| **Replay** | ‚úÖ Puede re-leer mensajes | ‚ùå No es posible |
| **Ordenamiento** | ‚úÖ Garantizado (por partici√≥n) | ‚ö†Ô∏è Mejor esfuerzo |
| **Throughput** | üöÄ Muy alto | üìä Moderado |

> üí° **En palabras simples:**
> 
> "Con Kafka, puedo almacenar mensajes por d√≠as y leerlos de nuevo si lo necesito. Siempre llegan en orden. Es como un video grabado que puedo volver a ver cuando quiera.
> 
> Con Pub/Sub tradicional, una vez que un mensaje se entrega, desaparece para siempre. No puedo reproducirlo. Es como una llamada telef√≥nica - si la pierdo, est√° perdida."

---

# üîµ PREGUNTAS_Y_RESPUESTAS_FUNDAMENTOS_GCP

---

## üìä 0. ¬øQu√© es BigQuery?

BigQuery es el **data warehouse serverless** de Google Cloud usado para almacenar y analizar grandes cantidades de datos muy r√°pidamente usando SQL.

| Caracter√≠stica | Descripci√≥n |
|----------------|-------------|
| üìä **Escala** | Terabytes a Petabytes |
| ‚ö° **Velocidad** | Segundos para queries complejos |
| üóÉÔ∏è **Interfaz** | SQL est√°ndar |
| üí∞ **Precios** | Pago por query o tarifa plana |
| üîß **Gesti√≥n** | Cero infraestructura |

---

## üéº 1. ¬øQu√© es Cloud Composer?

Cloud Composer es la versi√≥n gestionada de **Apache Airflow** de Google Cloud.

| Capacidad | Descripci√≥n |
|-----------|-------------|
| üìä **DAGs** | Define workflows como Directed Acyclic Graphs |
| ‚è∞ **Scheduling** | Programaci√≥n tipo cron |
| üîÑ **Dependencias** | Ordenamiento de tareas y reintentos |
| üîó **Integraciones** | BigQuery, Dataflow, Dataproc, GCS, APIs |
| üìà **Monitoreo** | UI web para seguimiento |

---

## üì¶ 2. ¬øQu√© es Cloud Storage (GCS)?

Cloud Storage es un servicio que te permite guardar datos en internet en lugar de en hardware f√≠sico.

| Clase de Almacenamiento | Caso de Uso | Costo |
|-------------------------|-------------|-------|
| üî• **Standard** | Acceso frecuente | üí∞üí∞üí∞ |
| üå°Ô∏è **Nearline** | Acceso mensual | üí∞üí∞ |
| ‚ùÑÔ∏è **Coldline** | Acceso trimestral | üí∞ |
| üßä **Archive** | Acceso anual | üíµ |

---

## üê≥ 3. ¬øQu√© es Cloud Run?

Cloud Run es un servicio de Google Cloud que te permite ejecutar **aplicaciones containerizadas** de forma serverless.

| Qu√© Puedes Ejecutar | Ejemplo |
|---------------------|---------|
| üîå APIs | Endpoints REST/GraphQL |
| üåê Web Apps | Aplicaciones frontend |
| üîß Microservicios | Servicios de l√≥gica de negocio |
| ‚öôÔ∏è Jobs en Segundo Plano | Tareas de procesamiento de datos |

---

## üîê 4. ¬øQu√© es Secret Manager?

Secret Manager te permite guardar tus secretos en la nube de forma segura y acceder a ellos solo cuando los necesitas.

| Almacena | Ejemplos |
|----------|----------|
| üîë Contrase√±as | Credenciales de base de datos |
| üé´ API Keys | Claves de servicios de terceros |
| üéüÔ∏è Tokens | OAuth, tokens JWT |
| üìú Certificados | Certificados SSL/TLS |

---

## üë§ 5. ¬øQu√© es IAM?

IAM (Identity and Access Management) es el sistema que controla **qui√©n puede acceder a qu√©** en un entorno cloud.

| Componente | Descripci√≥n |
|------------|-------------|
| üë§ **Users** | Identidades humanas |
| ü§ñ **Service Accounts** | Identidades de aplicaciones |
| üé≠ **Roles** | Colecciones de permisos |
| üîí **Policies** | Vinculaciones de roles a recursos |

---

## ‚ö° 6. ¬øQu√© es Bigtable?

Bigtable es la **base de datos NoSQL** de Google Cloud dise√±ada para grandes cantidades de datos con baja latencia.

| Mejor Para | Ejemplo |
|------------|---------|
| ‚è±Ô∏è Series temporales | M√©tricas, datos de sensores |
| üì± IoT | Telemetr√≠a de dispositivos |
| üíπ Financiero | Precios de acciones, transacciones |
| üéØ Recomendaciones | Preferencias de usuarios |

> üí° **Casos de Uso en palabras simples:**
> 
> "Uso Bigtable cuando necesito almacenar miles de millones de filas y leerlas muy r√°pido. Por ejemplo:
> - **Series temporales:** Almaceno m√©tricas del servidor cada segundo y consulto la √∫ltima hora instant√°neamente.
> - **IoT:** Recolecto datos de miles de sensores y analizo patrones en tiempo real.
> - **Financiero:** Rastrea cada cambio de precio de acciones y recupero datos hist√≥ricos en milisegundos.
> - **Recomendaciones:** Almaceno comportamiento del usuario para sugerir productos o contenido r√°pidamente."

---

## üåç 7. ¬øQu√© es Cloud Spanner?

Cloud Spanner es la **base de datos SQL globalmente escalable** y completamente gestionada de Google Cloud.

| Caracter√≠stica | Descripci√≥n |
|----------------|-------------|
| üåç **Global** | Replicaci√≥n multi-regi√≥n |
| üîí **Consistente** | Garant√≠as ACID fuertes |
| üìà **Escalable** | Escalado horizontal |
| üóÉÔ∏è **SQL** | Interfaz SQL est√°ndar |

**Casos de uso:** Apps financieras, e-commerce global, sistemas de inventario, backends de gaming.

### ‚öñÔ∏è Bigtable vs Cloud Spanner - ¬øCu√°l es la diferencia?

| Caracter√≠stica | ‚ö° Bigtable | üåç Cloud Spanner |
|----------------|-------------|------------------|
| **Tipo** | NoSQL (key-value) | SQL (relacional) |
| **Esquema** | Sin esquema | Esquema estructurado |
| **Lenguaje de Query** | Sin SQL, solo b√∫squedas por key | Soporte SQL completo |
| **Consistencia** | Eventualmente consistente | Transacciones ACID fuertes |
| **Joins** | ‚ùå No soportado | ‚úÖ Soportado |
| **Mejor Para** | Alto throughput, lecturas simples | Queries complejos, transacciones |

> üí° **¬øCu√°ndo uso cada uno?**
> 
> "Elijo entre Bigtable y Cloud Spanner seg√∫n mis necesidades de datos:
> - **Bigtable:** Lo uso cuando tengo cantidades masivas de datos con patrones de acceso simples. Por ejemplo, almaceno datos de series temporales donde solo leo por row key - no necesito queries complejos. Es extremadamente r√°pido para b√∫squedas de una sola key.
> - **Cloud Spanner:** Lo uso cuando necesito caracter√≠sticas SQL como JOINs y transacciones entre m√∫ltiples filas. Por ejemplo, una app bancaria donde necesito transferir dinero entre cuentas de forma at√≥mica - no puedo permitir inconsistencia.
> 
> Regla simple: Si necesito SQL y transacciones ‚Üí Spanner. Si necesito velocidad y escala con b√∫squedas simples ‚Üí Bigtable."

---

## ‚öñÔ∏è 8. Dataflow vs Dataproc vs BigQuery

| Servicio | Tipo | Mejor Para | Serverless |
|----------|------|------------|------------|
| üåä **Dataflow** | Procesamiento | ETL Streaming/Batch | ‚úÖ S√≠ |
| üî• **Dataproc** | Procesamiento | Jobs Spark/Hadoop | ‚ùå Clusters gestionados |
| üîµ **BigQuery** | Anal√≠tica | Queries SQL, BI | ‚úÖ S√≠ |

> üí° **¬øCu√°ndo uso cada uno?**
> 
> "Elijo seg√∫n lo que necesito hacer:
> - **Dataflow:** Lo uso cuando necesito procesar datos en streaming en tiempo real o ejecutar pipelines ETL batch. No gestiono servidores - escala autom√°ticamente.
> - **Dataproc:** Lo uso cuando tengo c√≥digo Spark o Hadoop existente y quiero ejecutarlo en la nube. Gestiono clusters pero GCP maneja la infraestructura.
> - **BigQuery:** Lo uso cuando quiero analizar datos que ya est√°n almacenados. Solo escribo queries SQL y obtengo resultados en segundos - no necesito pipelines de procesamiento."

---

### üîß 8.1 ¬øC√≥mo configuras un cluster de Dataproc?

> üí° **¬øHas configurado un cluster de Dataproc antes?**
> 
> "S√≠, he configurado muchos clusters de Dataproc para diferentes cargas de trabajo. As√≠ es como abordo la configuraci√≥n del cluster:"

**Par√°metros Clave de Configuraci√≥n:**

| Par√°metro | Descripci√≥n | Mi Recomendaci√≥n |
|-----------|-------------|------------------|
| üñ•Ô∏è **Master Node** | Coordina workers, ejecuta driver | `n1-standard-4` para la mayor√≠a de jobs |
| üë∑ **Worker Nodes** | Ejecutan tareas Spark | Empezar con 2-4, escalar seg√∫n datos |
| üìä **Machine Type** | CPU/Memoria por nodo | `n1-standard-4` a `n1-highmem-16` |
| üíæ **Disk Size** | Almacenamiento local por nodo | 100-500 GB SSD |
| üîÑ **Preemptible Workers** | M√°s baratos, pueden ser reclamados | Usar para jobs batch tolerantes a fallos |
| üì¶ **Image Version** | Versiones de Spark/Hadoop | `2.1-debian11` (Spark 3.3+) |

**Ejemplo: Crear un Cluster Dataproc (gcloud CLI)**

```bash
gcloud dataproc clusters create my-spark-cluster \
    --region=us-central1 \
    --zone=us-central1-a \
    --master-machine-type=n1-standard-4 \
    --master-boot-disk-size=100GB \
    --num-workers=2 \
    --worker-machine-type=n1-standard-4 \
    --worker-boot-disk-size=100GB \
    --num-secondary-workers=2 \
    --secondary-worker-type=preemptible \
    --image-version=2.1-debian11 \
    --initialization-actions=gs://my-bucket/init-scripts/install-packages.sh \
    --properties=spark:spark.executor.memory=4g,spark:spark.driver.memory=2g \
    --optional-components=JUPYTER,ANACONDA \
    --enable-component-gateway
```

**Ejemplo: Crear un Cluster Dataproc (Terraform)**

```hcl
resource "google_dataproc_cluster" "spark_cluster" {
  name   = "my-spark-cluster"
  region = "us-central1"

  cluster_config {
    master_config {
      num_instances = 1
      machine_type  = "n1-standard-4"
      disk_config {
        boot_disk_size_gb = 100
        boot_disk_type    = "pd-ssd"
      }
    }

    worker_config {
      num_instances = 2
      machine_type  = "n1-standard-4"
      disk_config {
        boot_disk_size_gb = 100
        boot_disk_type    = "pd-ssd"
      }
    }

    preemptible_worker_config {
      num_instances = 2
    }

    software_config {
      image_version = "2.1-debian11"
      override_properties = {
        "spark:spark.executor.memory" = "4g"
        "spark:spark.driver.memory"   = "2g"
      }
    }

    gce_cluster_config {
      zone        = "us-central1-a"
      subnetwork  = google_compute_subnetwork.default.id
      service_account = google_service_account.dataproc.email
    }
  }
}
```

**Enviar un Job de Spark:**

```bash
gcloud dataproc jobs submit pyspark gs://my-bucket/jobs/my_spark_job.py \
    --cluster=my-spark-cluster \
    --region=us-central1 \
    --properties=spark.executor.instances=4,spark.executor.memory=4g \
    -- --input=gs://my-bucket/data/input/ --output=gs://my-bucket/data/output/
```

**Mis Mejores Pr√°cticas de Configuraci√≥n:**

| Pr√°ctica | Por qu√© |
|----------|---------|
| üîÑ **Usar preemptible workers** | 60-80% ahorro en costos para jobs batch |
| üìä **Dimensionar correctamente** | Empezar peque√±o, monitorear, luego escalar |
| ‚è±Ô∏è **Configurar idle timeout** | Auto-eliminar clusters despu√©s de X minutos de inactividad |
| üîß **Usar initialization actions** | Instalar paquetes personalizados al crear cluster |
| üì¶ **Almacenar datos en GCS** | Separar almacenamiento de c√≥mputo para flexibilidad |
| üè∑Ô∏è **Agregar labels** | Rastrear costos por proyecto/equipo/ambiente |

> üéØ **Tip de Entrevista:** "Configuro clusters de Dataproc seg√∫n los requisitos de la carga de trabajo. Para desarrollo, uso clusters peque√±os con preemptible workers. Para producci√≥n, uso workers dedicados con auto-scaling. Siempre separo almacenamiento (GCS) de c√≥mputo para poder eliminar clusters cuando terminan los jobs y ahorrar costos. Tambi√©n uso Terraform para Infrastructure as Code para asegurar deployments reproducibles."

---

# üü† PREGUNTAS_Y_RESPUESTAS_FUNDAMENTOS_AWS

---

## üìä 0. Amazon Redshift (‚âà BigQuery)

Amazon Redshift es el data warehouse en la nube de AWS usado para almacenar y analizar datasets masivos con SQL.

| Caracter√≠stica | Descripci√≥n |
|----------------|-------------|
| üìä **Escala** | Petabytes de datos |
| ‚ö° **Velocidad** | Almacenamiento columnar, queries paralelos |
| üóÉÔ∏è **Interfaz** | SQL compatible con PostgreSQL |
| üí∞ **Precios** | On-demand o Reservado |
| üÜï **Serverless** | Redshift Serverless disponible |

---

## üéº 1. Amazon MWAA (‚âà Cloud Composer)

Amazon MWAA es el servicio gestionado de Apache Airflow de AWS.

| Caracter√≠stica | Descripci√≥n |
|----------------|-------------|
| üìä **DAGs** | Misma estructura de DAG de Airflow |
| üîó **Integraciones** | Redshift, Glue, EMR, S3, Lambda |
| üìà **Monitoreo** | CloudWatch + UI de Airflow |
| üîß **Gesti√≥n** | AWS maneja la infraestructura |

---

## üì¶ 2. Amazon S3 (‚âà Cloud Storage)

Amazon S3 es el servicio de almacenamiento de objetos en la nube de AWS.

| Clase de Almacenamiento | Caso de Uso | Costo |
|-------------------------|-------------|-------|
| üî• **Standard** | Acceso frecuente | üí∞üí∞üí∞ |
| üå°Ô∏è **Standard-IA** | Acceso infrecuente | üí∞üí∞ |
| ‚ùÑÔ∏è **Glacier** | Archivo (minutos para recuperar) | üí∞ |
| üßä **Glacier Deep** | Archivo a largo plazo (horas) | üíµ |

---

## üê≥ 3. AWS Fargate & Lambda (‚âà Cloud Run)

| Servicio | Tipo | Mejor Para |
|----------|------|------------|
| üê≥ **Fargate** | Contenedores serverless | Servicios de larga duraci√≥n, APIs |
| ‚ö° **Lambda** | Funciones serverless | Event-driven, tareas cortas |

---

## üîê 4. AWS Secrets Manager (‚âà Secret Manager)

Almacena de forma segura y **rota secretos autom√°ticamente**.

| Caracter√≠stica | Descripci√≥n |
|----------------|-------------|
| üîë **Almacenamiento** | Contrase√±as, API keys, tokens |
| üîÑ **Rotaci√≥n** | Rotaci√≥n autom√°tica de secretos |
| üîó **Integraci√≥n** | RDS, Redshift, Lambda |

---

## üë§ 5. AWS IAM (‚âà GCP IAM)

| Componente | Descripci√≥n |
|------------|-------------|
| üë§ **Users** | Identidades humanas |
| üé≠ **Roles** | Asumidos por servicios/usuarios |
| üìú **Policies** | Documentos JSON de permisos |
| üë• **Groups** | Colecciones de usuarios |

---

## ‚ö° 6. Amazon DynamoDB (‚âà Bigtable)

Amazon DynamoDB es la **base de datos NoSQL** de alto rendimiento de AWS.

| Caracter√≠stica | Descripci√≥n |
|----------------|-------------|
| ‚ö° **Latencia** | Milisegundos de un solo d√≠gito |
| üìà **Escala** | Throughput ilimitado |
| üåç **Global** | Global Tables para multi-regi√≥n |
| üí∞ **Precios** | On-demand o Provisioned |

> üí° **Casos de Uso en palabras simples:**
> 
> "Uso DynamoDB cuando necesito lecturas/escrituras s√∫per r√°pidas a cualquier escala. Por ejemplo:
> - **Gaming:** Almaceno sesiones de jugadores y leaderboards con actualizaciones instant√°neas.
> - **E-commerce:** Manejo carritos de compra y perfiles de usuario para millones de usuarios.
> - **Apps m√≥viles:** Almaceno datos de usuario que se sincronizan entre dispositivos en tiempo real.
> - **Ad tech:** Sirvo anuncios personalizados en milisegundos bas√°ndome en comportamiento del usuario."

---

## üåç 7. Amazon Aurora Global (‚âà Cloud Spanner)

| Caracter√≠stica | Aurora Global | DynamoDB Global Tables |
|----------------|---------------|------------------------|
| **Tipo** | SQL (MySQL/PostgreSQL) | NoSQL |
| **Consistencia** | Fuerte | Eventual |
| **Escala** | Replicaci√≥n global | Replicaci√≥n global |
| **Mejor Para** | Apps SQL tradicionales | Workloads key-value |

> üí° **Casos de Uso en palabras simples:**
> 
> "Elijo entre Aurora Global y DynamoDB Global Tables seg√∫n mis necesidades:
> - **Aurora Global:** Lo uso cuando necesito queries SQL y transacciones ACID globalmente. Por ejemplo, apps bancarias donde necesito consistencia fuerte para transferencias de dinero.
> - **DynamoDB Global Tables:** Lo uso cuando necesito b√∫squedas key-value r√°pidas globalmente. Por ejemplo, una app de gaming donde necesito leer perfiles de usuario r√°pidamente, y la consistencia eventual est√° bien."

---

## ‚öñÔ∏è 8. Servicios de Procesamiento AWS

| Servicio GCP | Equivalente AWS | Tipo |
|--------------|-----------------|------|
| üåä **Dataflow** | AWS Glue / Kinesis | ETL, Streaming |
| üî• **Dataproc** | Amazon EMR | Spark/Hadoop |
| üîµ **BigQuery** | Amazon Redshift | Data Warehouse |

### üî• ¬øQu√© es Amazon EMR?

Amazon EMR (Elastic MapReduce) es la **plataforma de big data gestionada** de AWS para ejecutar Spark, Hadoop, Hive y otros frameworks.

| Caracter√≠stica | Descripci√≥n |
|----------------|-------------|
| üîß **Frameworks** | Spark, Hadoop, Hive, Presto, Flink |
| üìà **Escala** | Clusters con auto-scaling |
| üí∞ **Precios** | Pago por hora de cluster |
| üóÉÔ∏è **Almacenamiento** | S3, HDFS, o EBS |

> üí° **¬øCu√°ndo uso EMR?**
> 
> "Uso Amazon EMR cuando:
> - Tengo **jobs Spark o Hadoop existentes** y quiero ejecutarlos en AWS.
> - Necesito control total sobre la configuraci√≥n del cluster y software instalado.
> - Quiero ejecutar workloads de **Hive, Presto, o Flink** - no solo Spark.
> 
> Por ejemplo, migro mis jobs Spark on-premise a EMR sin reescribir c√≥digo. Solo subo mis JARs, configuro el cluster y ejecuto."

### üîß ¬øC√≥mo configuras un cluster de Amazon EMR?

> üí° **¬øHas configurado un cluster EMR antes?**
> 
> "S√≠, he configurado clusters EMR para varias cargas de trabajo de Spark y Hadoop. As√≠ es como abordo la configuraci√≥n de EMR:"

**Par√°metros Clave de Configuraci√≥n:**

| Par√°metro | Descripci√≥n | Mi Recomendaci√≥n |
|-----------|-------------|------------------|
| üñ•Ô∏è **Master Node** | Coordina el cluster, ejecuta YARN | `m5.xlarge` para la mayor√≠a de jobs |
| üë∑ **Core Nodes** | Almacenan datos HDFS, ejecutan tareas | 2-4 nodos, escalar seg√∫n datos |
| üìä **Task Nodes** | Solo ejecutan tareas (sin HDFS) | Usar Spot instances para ahorrar costos |
| üíæ **Instance Type** | CPU/Memoria por nodo | `m5.xlarge` a `r5.4xlarge` |
| üì¶ **Release Label** | Versi√≥n de EMR (Spark/Hadoop) | `emr-6.10.0` (Spark 3.3+) |
| üîÑ **Spot Instances** | M√°s baratas, pueden ser interrumpidas | Usar para task nodes en jobs batch |

**Ejemplo: Crear un Cluster EMR (AWS CLI)**

```bash
aws emr create-cluster \
    --name "my-spark-cluster" \
    --release-label emr-6.10.0 \
    --applications Name=Spark Name=Hadoop Name=Hive \
    --instance-groups '[
        {
            "InstanceGroupType": "MASTER",
            "InstanceCount": 1,
            "InstanceType": "m5.xlarge",
            "Name": "Master"
        },
        {
            "InstanceGroupType": "CORE",
            "InstanceCount": 2,
            "InstanceType": "m5.xlarge",
            "Name": "Core"
        },
        {
            "InstanceGroupType": "TASK",
            "InstanceCount": 2,
            "InstanceType": "m5.xlarge",
            "Market": "SPOT",
            "Name": "Task"
        }
    ]' \
    --ec2-attributes KeyName=my-key,SubnetId=subnet-xxxxx \
    --use-default-roles \
    --log-uri s3://my-bucket/emr-logs/ \
    --configurations '[
        {
            "Classification": "spark-defaults",
            "Properties": {
                "spark.executor.memory": "4g",
                "spark.driver.memory": "2g",
                "spark.executor.instances": "4"
            }
        }
    ]' \
    --bootstrap-actions Path=s3://my-bucket/bootstrap/install-packages.sh,Name=InstallPackages \
    --auto-terminate \
    --steps '[
        {
            "Type": "Spark",
            "Name": "My Spark Job",
            "ActionOnFailure": "TERMINATE_CLUSTER",
            "Args": ["--deploy-mode", "cluster", "s3://my-bucket/jobs/my_spark_job.py"]
        }
    ]'
```

**Ejemplo: Crear un Cluster EMR (Terraform)**

```hcl
resource "aws_emr_cluster" "spark_cluster" {
  name          = "my-spark-cluster"
  release_label = "emr-6.10.0"
  applications  = ["Spark", "Hadoop", "Hive"]
  
  service_role = aws_iam_role.emr_service.arn
  
  ec2_attributes {
    subnet_id                         = aws_subnet.main.id
    emr_managed_master_security_group = aws_security_group.emr_master.id
    emr_managed_slave_security_group  = aws_security_group.emr_slave.id
    instance_profile                  = aws_iam_instance_profile.emr_ec2.arn
    key_name                          = "my-key"
  }

  master_instance_group {
    instance_type  = "m5.xlarge"
    instance_count = 1
    ebs_config {
      size = 100
      type = "gp3"
    }
  }

  core_instance_group {
    instance_type  = "m5.xlarge"
    instance_count = 2
    ebs_config {
      size = 100
      type = "gp3"
    }
  }

  configurations_json = jsonencode([
    {
      Classification = "spark-defaults"
      Properties = {
        "spark.executor.memory"    = "4g"
        "spark.driver.memory"      = "2g"
        "spark.executor.instances" = "4"
      }
    }
  ])

  log_uri = "s3://my-bucket/emr-logs/"

  tags = {
    Environment = "production"
    Project     = "data-platform"
  }
}
```

**Enviar un Job de Spark a EMR:**

```bash
# Agregar step a cluster en ejecuci√≥n
aws emr add-steps \
    --cluster-id j-XXXXXXXXXXXXX \
    --steps Type=Spark,Name="My Spark Job",ActionOnFailure=CONTINUE,\
Args=[--deploy-mode,cluster,--executor-memory,4g,s3://my-bucket/jobs/my_spark_job.py]

# O usar spark-submit directamente en el cluster
spark-submit \
    --deploy-mode cluster \
    --master yarn \
    --executor-memory 4g \
    --num-executors 4 \
    s3://my-bucket/jobs/my_spark_job.py \
    --input s3://my-bucket/data/input/ \
    --output s3://my-bucket/data/output/
```

**Mis Mejores Pr√°cticas de Configuraci√≥n:**

| Pr√°ctica | Por qu√© |
|----------|---------|
| üîÑ **Usar Spot para Task nodes** | 60-90% ahorro en costos, sin p√©rdida de datos si se interrumpe |
| üìä **Usar Core nodes para HDFS** | Almacenamiento estable, usar instancias On-Demand |
| ‚è±Ô∏è **Auto-terminate** | Eliminar cluster despu√©s de que complete el job |
| üîß **Bootstrap actions** | Instalar paquetes personalizados al crear cluster |
| üì¶ **Almacenar datos en S3** | Separar almacenamiento de c√≥mputo |
| üè∑Ô∏è **Usar tags** | Rastrear costos por proyecto/equipo/ambiente |
| üìù **Habilitar logging** | Enviar logs a S3 para debugging |

**Comparaci√≥n EMR vs Dataproc:**

| Caracter√≠stica | üî• Dataproc (GCP) | üî• EMR (AWS) |
|----------------|-------------------|--------------|
| **Tiempo de Inicio** | ~90 segundos | ~5-10 minutos |
| **Spot/Preemptible** | Preemptible workers | Spot instances |
| **Almacenamiento** | GCS | S3 / HDFS |
| **Precios** | Por segundo | Por segundo |
| **Opci√≥n Serverless** | Dataproc Serverless | EMR Serverless |
| **Integraci√≥n Notebook** | Jupyter v√≠a Component | EMR Studio |

> üéØ **Tip de Entrevista:** "Configuro clusters EMR seg√∫n los requisitos de la carga de trabajo. Para optimizaci√≥n de costos, uso Spot instances para Task nodes ya que no almacenan datos HDFS y pueden ser interrumpidos de forma segura. Siempre uso auto-termination para jobs batch y almaceno datos en S3 para separar almacenamiento de c√≥mputo. Para Infrastructure as Code, uso Terraform para versionar mis configuraciones de cluster y asegurar deployments reproducibles entre ambientes."

### üåä ¬øFunciona Apache Beam en AWS como Dataflow?

| Runner | Plataforma | Descripci√≥n |
|--------|------------|-------------|
| üåä **Dataflow Runner** | GCP | Nativo, completamente gestionado |
| üî• **Spark Runner** | EMR / Dataproc | Ejecutar Beam en clusters Spark |
| üåÄ **Flink Runner** | EMR / Kinesis Data Analytics | Ejecutar Beam en Flink |

> üí° **En palabras simples:**
> 
> "Apache Beam es el **c√≥digo que escribo**, y el runner es **donde se ejecuta**:
> - En **GCP**, uso Dataflow Runner - es nativo y serverless.
> - En **AWS**, puedo ejecutar mi c√≥digo Beam en **EMR usando Spark Runner** o **Flink Runner**. No es serverless como Dataflow, pero mi c√≥digo Beam funciona igual.
> 
> As√≠ que s√≠, puedo escribir pipelines Beam una vez y ejecutarlos tanto en GCP (Dataflow) como en AWS (EMR con Spark/Flink). Ese es el poder de Beam - escribe una vez, ejecuta en cualquier lugar!"

### üîÑ AWS Glue vs Kinesis - ¬øCu√°l es la diferencia?

| Caracter√≠stica | üîß AWS Glue | üåä Kinesis |
|----------------|-------------|------------|
| **Prop√≥sito** | ETL (Extract, Transform, Load) | Streaming en tiempo real |
| **Tipo de Datos** | Datos batch | Streams continuos |
| **Latencia** | Minutos a horas | Milisegundos a segundos |
| **Caso de Uso** | Data warehousing, data lakes | Dashboards en vivo, alertas |

> üí° **¬øCu√°ndo uso cada uno?**
> 
> "Elijo entre Glue y Kinesis seg√∫n el timing:
> - **AWS Glue:** Lo uso cuando necesito mover y transformar datos en batches. Por ejemplo, cada noche extraigo datos de bases de datos, los transformo y los cargo en Redshift.
> - **Kinesis:** Lo uso cuando necesito procesar datos a medida que llegan. Por ejemplo, hago streaming de datos de clickstream desde mi sitio web y analizo el comportamiento del usuario en tiempo real.
> 
> A veces uso ambos juntos: Kinesis captura eventos en tiempo real, y Glue los procesa en batches para almacenamiento a largo plazo."

---

# üéØ PREGUNTAS_Y_RESPUESTAS_PREPARACION_ENTREVISTA

> **Nota:** Las respuestas a continuaci√≥n est√°n basadas en experiencia personal. Cada Data Engineer tiene un background diferente, as√≠ que adapta estas respuestas para reflejar tu propio camino.
> 
> üìã **Esta secci√≥n incluye:** Criterios de Evaluaci√≥n Senior + Preguntas y Respuestas de Entrevista (Q1-Q30)

---

## üéØ ¬øQu√© eval√∫an las empresas para Senior Data Engineer?

| √Årea | Qu√© Eval√∫an |
|------|-------------|
| üìö **Fundamentos** | SQL avanzado (CTEs, window functions, rendimiento), Python productivo, testing |
| üîÑ **Data Pipelines** | Spark/dbt/Airflow, orquestaci√≥n, particiones/clustering, manejo de fallos |
| üèóÔ∏è **Arquitectura & Cloud** | Modelado de datos (3NF/OLAP/OBT), patrones CDC, costo y rendimiento en BigQuery/Redshift |
| ‚úÖ **Confiabilidad** | SLAs/SLOs, monitoreo, calidad de datos (checks/expectations), versionado & IaC |

> üí° **C√≥mo me preparo para entrevistas Senior:**
> 
> "Cuando entrevisto para roles Senior, me enfoco en estas 4 √°reas:
> 
> - **Fundamentos:** Practico SQL avanzado - CTEs para legibilidad, window functions para rankings y totales acumulados, y optimizaci√≥n de queries. Escribo Python limpio con testing apropiado y manejo de errores.
> 
> - **Data Pipelines:** Puedo explicar mis jobs de Spark, modelos de dbt, y DAGs de Airflow en detalle. S√© por qu√© particiono por fecha, por qu√© hago clustering por ciertas columnas, y c√≥mo manejo fallos con reintentos y dead-letter queues.
> 
> - **Arquitectura:** Entiendo diferentes modelos de datos - cu√°ndo usar 3NF vs star schema vs One Big Table. Conozco patrones CDC para sincronizaci√≥n de datos en tiempo real. Puedo discutir optimizaci√≥n de costos en BigQuery (particionado, clustering, slot reservations) o Redshift (distribution keys, sort keys).
> 
> - **Confiabilidad:** Defino SLAs con stakeholders, configuro monitoreo y alertas, implemento checks de calidad de datos, y uso Infrastructure as Code (Terraform) para deployments reproducibles.
> 
> La clave a nivel Senior no es solo saber C√ìMO hacer las cosas, sino POR QU√â tomas ciertas decisiones y CU√ÅNDO usar cada enfoque."

---

## üü¢ SECCI√ìN 1 ‚Äî Background y Experiencia T√©cnica (Q1-Q9)

---

### üñ•Ô∏è Q1. Experiencia con Spark On-Premise vs Cloud

| Ambiente | Experiencia |
|----------|-------------|
| üè¢ **On-Premise** | Clusters Hadoop/YARN, gesti√≥n de recursos, tuning |
| ‚òÅÔ∏è **Cloud** | Dataproc (GCP), EMR (AWS), escalado simplificado |

> ‚úÖ C√≥modo con ambos ambientes, entendiendo deployment, optimizaci√≥n y diferencias de costo.

> üí° **Mi experiencia en palabras simples:**
> 
> "**On-Premise:** Gestion√© clusters Hadoop con YARN. Ten√≠a que configurar manualmente memoria, CPU y executors. Cuando un job fallaba, revisaba logs en m√∫ltiples nodos. Escalar significaba comprar nuevos servidores y esperar semanas. Pas√© mucho tiempo tuneando shuffle partitions, asignaci√≥n de memoria y arreglando errores de out-of-memory.
> 
> **Cloud:** Ahora uso Dataproc o EMR. Levanto un cluster en minutos, ejecuto mi job y lo elimino. Auto-scaling agrega workers cuando los necesito. No me preocupo por hardware - solo me enfoco en mi c√≥digo Spark. Si necesito m√°s poder, cambio el tipo de m√°quina y reinicio.
> 
> **Diferencias clave que not√©:**
> - **Costo:** On-premise = costo fijo (comprar servidores). Cloud = pago por uso (puede ser m√°s barato o m√°s caro dependiendo del uso).
> - **Velocidad:** On-premise = semanas para escalar. Cloud = minutos para escalar.
> - **Control:** On-premise = control total pero m√°s responsabilidad. Cloud = menos control pero menos mantenimiento.
> - **Tuning:** El mismo tuning de Spark aplica a ambos, pero cloud me da m√°s flexibilidad para experimentar r√°pidamente."

---

### üóÑÔ∏è Q2. Experiencia con Bases de Datos Enterprise (Oracle & SQL Server)

| Base de Datos | Experiencia |
|---------------|-------------|
| üü• **Oracle** | ETL con PL/SQL, particionado, integraci√≥n GoldenGate/CDC |
| üü¶ **SQL Server** | Optimizaci√≥n de SSIS (SQL Server Integration Services), Always On AG, stored procedures |

| Patr√≥n de Integraci√≥n | Herramientas Usadas |
|-----------------------|---------------------|
| üì§ CDC a Cloud | Datastream, AWS DMS, Debezium |
| üîÑ Rutinas ETL | PL/SQL, SSIS, stored procedures |
| üìä Integraci√≥n BI | Views, stored procedures para Spark/herramientas BI |

> üí° **Mi experiencia en palabras simples:**
> 
> "**Oracle:** Escrib√≠ procedimientos PL/SQL para jobs ETL que corr√≠an cada noche. Us√© particionado para manejar tablas grandes - por ejemplo, particionando por fecha para que los queries solo escaneen datos relevantes. Configur√© GoldenGate para CDC (Change Data Capture) en tiempo real para replicar datos a nuestro data lake sin impactar producci√≥n.
> 
> **SQL Server:** Constru√≠ paquetes SSIS para integraci√≥n de datos - extrayendo de m√∫ltiples fuentes, transformando y cargando al warehouse. Configur√© Always On Availability Groups para alta disponibilidad. Optimic√© stored procedures que las herramientas BI llamaban directamente.
> 
> **C√≥mo integro bases de datos enterprise con cloud moderno:**
> - **CDC a Cloud:** Uso Datastream (GCP), AWS DMS, o Debezium para capturar cambios en tiempo real y streamearlos a BigQuery, Redshift, o data lakes. De esta forma, no necesito jobs batch pesados - los datos fluyen continuamente.
> - **Rutinas ETL:** A veces mantengo jobs PL/SQL o SSIS existentes porque funcionan bien. No reescribo todo - solo conecto su salida a almacenamiento cloud.
> - **Integraci√≥n BI:** Creo views y stored procedures que Spark o herramientas BI pueden consultar. Esto da a los analistas una interfaz limpia sin exponer estructuras de tabla complejas."

---

### ‚ö° Q3. Funciones Serverless en Data Engineering

| Caso de Uso | Implementaci√≥n |
|-------------|----------------|
| üìã Validaci√≥n de Esquema | Validar al llegar el archivo |
| üè∑Ô∏è Enriquecimiento de Metadata | Agregar tags y contexto |
| üîî Trigger Downstream | Iniciar jobs Spark, enviar notificaciones |
| üîå Integraci√≥n API | Conectar servicios externos |

> üí° **Mi experiencia en palabras simples:**
> 
> "Uso funciones serverless (Cloud Functions, Lambda) para tareas ligeras que no necesitan un job Spark completo:
> 
> - **Validaci√≥n de Esquema:** Cuando un archivo llega a GCS o S3, mi funci√≥n se dispara autom√°ticamente. Verifica si el archivo tiene las columnas y tipos de datos correctos. Si la validaci√≥n falla, muevo el archivo a una carpeta de error y env√≠o una alerta.
> 
> - **Enriquecimiento de Metadata:** Agrego metadata como timestamp de procesamiento, sistema fuente y tama√±o de archivo a cada registro antes de que vaya al data lake. Esto ayuda con debugging y auditor√≠a despu√©s.
> 
> - **Trigger Downstream:** Despu√©s de que un archivo es validado, mi funci√≥n inicia un job de Dataproc o env√≠a un mensaje a Pub/Sub. Esto crea un pipeline event-driven sin intervenci√≥n manual.
> 
> - **Integraci√≥n API:** Llamo APIs externas para enriquecer datos - por ejemplo, obtener tasas de cambio de moneda o geocodificar direcciones. Las funciones son perfectas porque escalan autom√°ticamente y solo pago cuando se ejecutan."

---

### üéº Q4. Experiencia con Herramientas de Orquestaci√≥n

| Herramienta | Cloud | Experiencia |
|-------------|-------|-------------|
| üéº **Airflow/Composer** | GCP | DAGs, orquestaci√≥n batch/streaming |
| üéº **MWAA** | AWS | Mismas capacidades de Airflow |
| ‚öôÔ∏è **Step Functions** | AWS | Workflows event-driven |
| üè≠ **Data Factory** | Azure | Orquestaci√≥n de pipelines |

> üí° **Mi experiencia en palabras simples:**
> 
> "Uso herramientas de orquestaci√≥n para programar y coordinar mis pipelines de datos:
> 
> - **Airflow/Composer (GCP):** Esta es mi herramienta principal. Escribo DAGs (Directed Acyclic Graphs) en Python para definir dependencias de tareas. Por ejemplo: extraer datos ‚Üí validar ‚Üí transformar ‚Üí cargar ‚Üí enviar notificaci√≥n. Si un paso falla, Airflow lo reintenta y me alerta. Uso Composer porque es gestionado - no me preocupo por la infraestructura de Airflow.
> 
> - **MWAA (AWS):** Igual que Composer pero en AWS. Mis DAGs de Airflow funcionan en ambos con cambios m√≠nimos. Solo actualizo las conexiones y operadores (ej. GCS a S3, BigQuery a Redshift).
> 
> - **Step Functions (AWS):** Lo uso para workflows event-driven. A diferencia de Airflow (programado), Step Functions reaccionan a eventos inmediatamente. Por ejemplo, cuando llega un archivo, dispara un Lambda, luego otro Lambda, luego un job de EMR - todo definido como una m√°quina de estados.
> 
> - **Data Factory (Azure):** Concepto similar pero nativo de Azure. Lo he usado para orquestar pipelines que mueven datos entre SQL Server on-premise y Azure Synapse.
> 
> **¬øCu√°ndo elijo cada uno?**
> - Pipelines batch complejos con muchas dependencias ‚Üí Airflow/Composer/MWAA
> - Reacciones event-driven en tiempo real ‚Üí Step Functions
> - Ecosistema Azure ‚Üí Data Factory"

---

### üìä Q5. Dataform y Herramientas de Transformaci√≥n SQL

| Herramienta | Cloud | Prop√≥sito |
|-------------|-------|-----------|
| üìä **Dataform** | GCP | Transformaciones SQL en BigQuery |
| üîß **dbt (data build tool)** | AWS/GCP | Transformaciones SQL (funciona con Redshift, BigQuery, Snowflake) |

> üí° **Mi experiencia en palabras simples:**
> 
> "Uso Dataform y herramientas similares para transformar datos **dentro** del warehouse usando SQL:
> 
> - **Dataform (GCP):** Escribo modelos SQL que transforman datos raw en tablas limpias en BigQuery. Dataform maneja dependencias - si tabla A depende de tabla B, ejecuta B primero. Tambi√©n escribo tests para validar calidad de datos (ej. sin nulls en columnas clave). Es como 'control de versiones para transformaciones SQL'.
> 
> - **dbt (AWS):** Mismo concepto que Dataform pero lo uso con Redshift en AWS. La sintaxis es casi id√©ntica a Dataform, as√≠ que cambiar entre ellos es f√°cil.
> 
> **Dataform vs Herramientas de Orquestaci√≥n - ¬øCu√°l es la diferencia?**
> - **Airflow/Step Functions:** Orquestan jobs *externos* (Spark, APIs, movimientos de archivos)
> - **Dataform/dbt:** Transforman datos *dentro* del warehouse solo con SQL
> 
> A menudo uso ambos juntos: Airflow dispara el job de Dataform/dbt, que luego ejecuta todas mis transformaciones SQL en el orden correcto."

---

### üé§ Q6. Cu√©ntame sobre tu background como Data Engineer.

| Aspecto | Mi Experiencia |
|---------|----------------|
| ‚òÅÔ∏è **Plataformas Cloud** | GCP & AWS |
| üèóÔ∏è **Arquitectura** | Data lakes, pipelines en tiempo real, sistemas de anal√≠tica |
| üîß **Herramientas** | Airflow, Dataform, Lambda, Cloud Functions, Kinesis, Kafka |
| üÜï **Enfoque Reciente** | Generative AI: RAG, agentes inteligentes, sistemas de monitoreo |

> üí° **C√≥mo respondo esto:**
> 
> "Soy un Data Engineer con experiencia en GCP y AWS. He construido data lakes desde cero, dise√±ado pipelines de streaming en tiempo real, y creado sistemas de anal√≠tica que soportan decisiones de negocio. Mis herramientas diarias incluyen Airflow para orquestaci√≥n, Dataform para transformaciones SQL, y funciones serverless para procesamiento ligero. Recientemente, me he enfocado en Generative AI - construyendo sistemas RAG y agentes inteligentes que combinan data engineering tradicional con capacidades modernas de IA."

---

### üõ†Ô∏è Q7. ¬øQu√© herramientas usas diariamente?

| Categor√≠a | Herramientas |
|-----------|--------------|
| üìä **Data Warehouses** | BigQuery, Redshift |
| üîÑ **ETL/ELT** | Dataform, dbt |
| üéº **Orquestaci√≥n** | Airflow, Cloud Composer, MWAA |
| ‚ö° **Serverless** | Cloud Functions, Lambda |
| üì¶ **Almacenamiento** | S3, GCS |
| üì® **Streaming** | Kafka, Kinesis |
| ü§ñ **AI/ML** | Vertex AI, AutoML |
| üîß **DevOps** | GitHub, Cloud Build, Docker |
| üÜï **GenAI** | LangGraph, Agent Builder, ADK |

> üí° **C√≥mo respondo esto:**
> 
> "Cada d√≠a trabajo con BigQuery o Redshift para anal√≠tica - escribiendo SQL, optimizando queries y gestionando tablas. Uso Dataform o dbt para transformar datos raw en modelos limpios. Airflow es mi herramienta principal para programar y orquestar pipelines. Para tareas ligeras, uso Cloud Functions o Lambda - se disparan autom√°ticamente cuando llegan archivos. Almaceno todo en S3 o GCS. Cuando necesito procesamiento en tiempo real, uso Kafka o Kinesis. Recientemente, he estado usando LangGraph y Agent Builder para crear soluciones de datos impulsadas por IA."

---

### üè≠ Q8. ¬øEn qu√© industrias has trabajado?

| Industria | √Årea de Enfoque |
|-----------|-----------------|
| üìä **Marketing Analytics** | Rendimiento de campa√±as, atribuci√≥n |
| üìû **Operaciones de Call Center** | Insights de clientes, sentimiento |
| üìà **Business Intelligence** | Dashboards, reportes |
| ü§ñ **Desarrollo de AI Agents** | IA conversacional, automatizaci√≥n |
| ‚òÅÔ∏è **Automatizaci√≥n Cloud** | Infraestructura, DevOps |

> üí° **C√≥mo respondo esto:**
> 
> "He trabajado en varias industrias. En Marketing Analytics, constru√≠ pipelines que rastrean rendimiento de campa√±as a trav√©s de m√∫ltiples plataformas de ads - ayudando a marketers a entender ROI y atribuci√≥n. En Operaciones de Call Center, analic√© interacciones de clientes para extraer insights sobre sentimiento y problemas comunes. Tambi√©n he construido sistemas de Business Intelligence - creando dashboards y reportes que ejecutivos usan para toma de decisiones. Recientemente, he estado desarrollando AI Agents para interfaces conversacionales y automatizando infraestructura cloud."

---

### üéì Q9. ¬øQu√© certificaciones tienes?

| Certificaci√≥n | Proveedor | Estado |
|---------------|-----------|--------|
| üîµ **Professional Data Engineer** | Google Cloud | ‚úÖ Certificado |
| ü§ñ **Generative AI Leader** | Google Cloud | ‚úÖ Certificado |
| üåê **Ingl√©s B2** | Cambridge/TOEFL | ‚úÖ Certificado |
| üìö **Skills Boost Training** | Google Cloud | ‚úÖ Completado |

> üí° **C√≥mo respondo esto:**
> 
> "Soy Professional Data Engineer certificado por Google Cloud - esta certificaci√≥n valida mis habilidades en dise√±o y construcci√≥n de sistemas de procesamiento de datos en GCP. Tambi√©n tengo la certificaci√≥n de Generative AI Leader, que cubre sistemas RAG, prompt engineering y AI agents. Complet√© entrenamiento extensivo a trav√©s de Google Cloud Skills Boost. Mi ingl√©s tiene certificaci√≥n B2, lo que me permite comunicarme efectivamente en equipos internacionales."

---

## üü° SECCI√ìN 2 ‚Äî Preguntas Intermedias (Q10-Q13)

---

### üìä Q10. Describe un pipeline ETL t√≠pico que hayas construido.

```
FUENTES DE DATOS ‚Üí INGESTA ‚Üí TRANSFORMACI√ìN ‚Üí SALIDA
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚Ä¢ Google Ads     ‚Ä¢ APIs           ‚Ä¢ Dataform        ‚Ä¢ Dashboards
‚Ä¢ Meta           ‚Ä¢ S3/GCS         ‚Ä¢ BigQuery SQL    ‚Ä¢ Tiempo real
‚Ä¢ TikTok         ‚Ä¢ Validaci√≥n     ‚Ä¢ Airflow         ‚Ä¢ Alertas
‚Ä¢ LinkedIn       ‚Ä¢ Cloud Build    ‚Ä¢ CI/CD           ‚Ä¢ Reportes
‚Ä¢ X (Twitter)
```

> üí° **C√≥mo respondo esto:**
> 
> "Constru√≠ un pipeline de marketing analytics que extrae datos de m√∫ltiples plataformas de ads - Google Ads, Meta, TikTok, LinkedIn y X. Cada d√≠a, mi pipeline llama a sus APIs para extraer datos de campa√±as. Los datos raw llegan a GCS, luego Cloud Functions validan el esquema. Si la validaci√≥n pasa, Dataform transforma los datos - limpiando, uniendo y calculando m√©tricas. Airflow orquesta todo el flujo y env√≠a alertas si algo falla. Las tablas finales alimentan dashboards donde los marketers rastrean rendimiento de campa√±as en casi tiempo real."

---

### ‚úÖ Q11. ¬øC√≥mo aseguras la calidad de datos?

| Tipo de Validaci√≥n | Implementaci√≥n | Impacto |
|--------------------|----------------|---------|
| üîç **Null Checks** | Automatizado despu√©s de ingesta | Captura datos faltantes |
| üìê **Schema Drift** | Comparar esperado vs actual | Prevenir cambios que rompen |
| ‚è∞ **Pol√≠ticas de Freshness** | Alertar sobre datos viejos | Asegurar oportunidad |
| üìä **Alertas de Threshold** | Detecci√≥n de anomal√≠as | Capturar outliers |
| üîÑ **Reconciliaci√≥n** | Comparar contra APIs fuente | Asegurar completitud |

> üìà **Resultado:** Reducci√≥n de fallos en pipeline de marketing en **60%**.

> üí° **C√≥mo respondo esto:**
> 
> "La calidad de datos es cr√≠tica en mis pipelines. Primero, ejecuto null checks justo despu√©s de la ingesta - si columnas clave est√°n vac√≠as, el pipeline se detiene y me alerta. Segundo, detecto schema drift comparando datos entrantes contra esquemas esperados - esto nos salv√≥ muchas veces cuando las APIs cambiaron sin aviso. Tercero, configuro pol√≠ticas de freshness - si los datos son m√°s viejos de lo esperado, recibo una alerta. Cuarto, uso alertas de threshold para detecci√≥n de anomal√≠as - si las m√©tricas suben o bajan s√∫bitamente, algo podr√≠a estar mal. Finalmente, reconcilio nuestros datos contra las APIs fuente para asegurar que no perdimos ning√∫n registro. Estas pr√°cticas redujeron nuestros fallos de pipeline en 60%."

---

### ‚ö° Q12. ¬øC√≥mo optimizas el rendimiento de BigQuery o Redshift?

| Optimizaci√≥n | BigQuery | Redshift |
|--------------|----------|----------|
| üìÖ **Particionado** | Por fecha/timestamp | Por columna de fecha |
| üéØ **Clustering** | Por columnas de alta cardinalidad | Sort keys |
| üìä **Materialized Views** | ‚úÖ Soportado | ‚úÖ Soportado |
| üîç **Query Pruning** | Filtrado de predicados | Predicate pushdown |
| üèóÔ∏è **Distribution** | N/A | Estrategia DISTKEY |
| ‚ùå **Evitar** | SELECT * | SELECT * |

> ‚ö° **Resultado:** Tiempos de query reducidos de **minutos a segundos**.

> üí° **C√≥mo respondo esto:**
> 
> "Optimizo BigQuery y Redshift usando varias t√©cnicas. Primero, particionado - siempre particiono por fecha para que los queries solo escaneen datos relevantes. Un query para '√∫ltimos 7 d√≠as' escanea 7 particiones en lugar de toda la tabla. Segundo, clustering (BigQuery) o sort keys (Redshift) - hago clustering por columnas frecuentemente usadas en cl√°usulas WHERE. Tercero, creo materialized views para agregaciones complejas que se consultan frecuentemente. Cuarto, nunca uso SELECT * - solo selecciono las columnas que necesito. En Redshift, tambi√©n elijo la distribution key correcta para minimizar shuffling de datos. Estas optimizaciones redujeron tiempos de query de minutos a segundos."

---

### üåä Q13. Cu√©ntame sobre tu experiencia con streaming en tiempo real.

| Plataforma | Caso de Uso | Caracter√≠sticas |
|------------|-------------|-----------------|
| üì® **Kinesis** | Eventos de clientes, tracking de marketing | Nativo de AWS, auto-scaling |
| üì® **Kafka** | Pipelines event-driven | Alto throughput, replay |

> üí° **C√≥mo respondo esto:**
> 
> "He trabajado con Kinesis y Kafka para streaming en tiempo real. Con Kinesis, constru√≠ un pipeline que captura eventos de clientes desde nuestro sitio web - clicks, page views, env√≠os de formularios. Los datos fluyen a Kinesis, Lambda los procesa, y en segundos est√°n disponibles para an√°lisis. Con Kafka, constru√≠ pipelines event-driven donde m√∫ltiples consumers leen de los mismos topics. La ventaja clave de Kafka es replay - si algo sale mal, puedo reprocesar mensajes desde cualquier punto en el tiempo. Elijo Kinesis cuando estoy completamente en AWS y necesito simplicidad. Elijo Kafka cuando necesito alto throughput, capacidades de replay, o escenarios multi-consumer."

---

## üî¥ SECCI√ìN 3 ‚Äî Preguntas Avanzadas Senior (Q14-Q20)

---

### üèóÔ∏è Q14. Describe c√≥mo dise√±as una arquitectura de datos cloud escalable.

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      ARQUITECTURA DE DATOS ESCALABLE                         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  INGESTA     ‚Üí    ALMACENAMIENTO   ‚Üí    C√ìMPUTO      ‚Üí    SEM√ÅNTICA         ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ       ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ       ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ           ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ         ‚îÇ
‚îÇ  ‚Ä¢ APIs           ‚Ä¢ Zona Raw            ‚Ä¢ Dataform        ‚Ä¢ Capa BI         ‚îÇ
‚îÇ  ‚Ä¢ Streaming      ‚Ä¢ (S3/GCS)            ‚Ä¢ Spark           ‚Ä¢ Modelos ML      ‚îÇ
‚îÇ  ‚Ä¢ Batch          ‚Ä¢ Staging             ‚Ä¢ Airflow         ‚Ä¢ APIs            ‚îÇ
‚îÇ  ‚Ä¢ CDC            ‚Ä¢ Modelado                                                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  TRANSVERSAL: CI/CD | Monitoreo | Logging | Alertas | Gesti√≥n de Costos     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

> üí° **C√≥mo respondo esto:**
> 
> "Dise√±o arquitecturas de datos en capas. Primero, la capa de Ingesta - extraigo datos de APIs, fuentes streaming, archivos batch, y CDC desde bases de datos. Todos los datos raw llegan a una Zona Raw (S3/GCS) - nunca modifico datos fuente. Segundo, la capa de Almacenamiento con zonas staging y modeladas. Tercero, la capa de C√≥mputo donde Dataform/dbt transforma datos y Spark maneja procesamiento pesado. Finalmente, la capa Sem√°ntica expone datos limpios a herramientas BI y modelos ML.
> 
> A trav√©s de todas las capas, implemento CI/CD para deployments, monitoreo para salud del pipeline, logging para debugging, alertas para fallos, y gesti√≥n de costos para evitar sorpresas. Esta arquitectura escala porque cada capa puede escalar independientemente."

---

### ü§ñ Q15. ¬øC√≥mo abordas el dise√±o de sistemas RAG?

| Componente | Implementaci√≥n |
|------------|----------------|
| ‚úÇÔ∏è **Chunking** | Optimizado para tipo de contenido (marketing, soporte) |
| üî¢ **Embeddings** | Modelos tuneados para el dominio |
| üóÉÔ∏è **Vector Store** | Vertex Matching Engine, Supabase, Pinecone |
| üîÄ **Context Routing** | Clasificaci√≥n de queries + cadenas de retrieval |
| üõ°Ô∏è **Fallbacks** | Respuestas basadas en reglas, filtros de seguridad |
| üìä **Evaluaci√≥n** | Tests de regresi√≥n, scores de similitud |

> üí° **C√≥mo respondo esto:**
> 
> "Cuando dise√±o sistemas RAG, empiezo con la estrategia de chunking - optimizo el tama√±o de chunk seg√∫n el tipo de contenido. El contenido de marketing necesita chunking diferente que la documentaci√≥n t√©cnica. Luego elijo modelos de embeddings - a veces los fine-tuneo para nuestro dominio. Para almacenamiento vectorial, uso Vertex Matching Engine en GCP o Pinecone para multi-cloud. Implemento context routing para clasificar queries y elegir la estrategia de retrieval correcta. Siempre agrego fallbacks para cuando el retrieval falla. Finalmente, configuro evaluaci√≥n con tests de regresi√≥n y scores de similitud para asegurar calidad en el tiempo."

---

### ü§ñ Q16. Explica c√≥mo construyes agentes de IA inteligentes.

| Paso | Descripci√≥n | Herramientas |
|------|-------------|--------------|
| 1Ô∏è‚É£ **Persona** | Definir comportamiento del sistema y restricciones | Prompt engineering |
| 2Ô∏è‚É£ **Tools** | B√∫squeda, memoria, retrieval, acciones de API | LangGraph, ADK |
| 3Ô∏è‚É£ **Conversaci√≥n** | L√≥gica multi-turno | Gesti√≥n de estado |
| 4Ô∏è‚É£ **Fallbacks** | Manejo de errores, escalaci√≥n | Filtros de seguridad |
| 5Ô∏è‚É£ **Monitoreo** | Confiabilidad, consistencia de marca | Logging, m√©tricas |
| 6Ô∏è‚É£ **Evaluaci√≥n** | Tests A/B, regresi√≥n | Testing automatizado |

> üí° **C√≥mo respondo esto:**
> 
> "Construyo agentes de IA en 6 pasos. Primero, defino la persona - qu√© debe hacer el agente y qu√© restricciones tiene. Segundo, le doy tools - b√∫squeda, memoria, retrieval, y acciones de API usando LangGraph o ADK. Tercero, implemento l√≥gica de conversaci√≥n para interacciones multi-turno con gesti√≥n de estado apropiada. Cuarto, agrego fallbacks para cuando las cosas salen mal - manejo de errores y escalaci√≥n a humanos. Quinto, configuro monitoreo para rastrear confiabilidad y asegurar consistencia de marca. Finalmente, creo pipelines de evaluaci√≥n con tests A/B y testing de regresi√≥n para medir calidad."

---

### üîî Q17. ¬øC√≥mo dise√±as sistemas de alertas y monitoreo?

| Tipo de Alerta | Trigger | Canal | Prioridad |
|----------------|---------|-------|-----------|
| üìà **Keyword Spikes** | Volumen > threshold | Slack | üü° Media |
| üò† **Anomal√≠a de Sentimiento** | Negativo > 2œÉ | PagerDuty | üî¥ Alta |
| ü§ñ **Detecci√≥n de Spam** | Patr√≥n match | Slack | üü° Media |
| üìä **Ca√≠da de Rendimiento** | M√©tricas bajan | Email | üü† Alta |
| ‚è∞ **Freshness de Datos** | Stale > 2 horas | PagerDuty | üî¥ Cr√≠tica |

> üí° **C√≥mo respondo esto:**
> 
> "Dise√±o alertas basadas en prioridad y urgencia. Para issues cr√≠ticos como freshness de datos (stale > 2 horas), uso PagerDuty para despertar a alguien si es necesario. Para issues de alta prioridad como anomal√≠as de sentimiento, tambi√©n uso PagerDuty pero con diferentes reglas de escalaci√≥n. Para prioridad media como keyword spikes, Slack es suficiente - el equipo lo ve durante horario de trabajo. Siempre defino thresholds claros y evito fatiga de alertas tuneando la sensibilidad. Cada alerta incluye contexto: qu√© pas√≥, por qu√© importa, y c√≥mo investigar."

---

### üí™ Q18. Describe un problema desafiante y c√≥mo lo resolviste.

| Fase | Descripci√≥n |
|------|-------------|
| üî¥ **Problema** | Pipeline de marketing se romp√≠a por cambios de schema en APIs de terceros |
| üîç **Causa Ra√≠z** | Sin validaci√≥n de schema, transformaciones fr√°giles |

| Soluci√≥n | Implementaci√≥n |
|----------|----------------|
| üìê **Detecci√≥n de Schema** | Inferencia autom√°tica de schema en ingesta |
| üîî **Alertas de Drift** | Notificar cambios de schema |
| üîÑ **Auto-Reparaci√≥n** | Transformaciones flexibles |
| ‚úÖ **Validaci√≥n** | Checks pre-carga |

> üìà **Resultado:** Reducci√≥n de fallos en **60%**, reportes estabilizados.

> üí° **C√≥mo respondo esto:**
> 
> "Uno de mis mayores desaf√≠os fue cuando nuestro pipeline de marketing segu√≠a rompi√©ndose aleatoriamente. Despu√©s de investigar, encontr√© la causa ra√≠z: las APIs de terceros (Google Ads, Meta) a veces cambiaban sus schemas de respuesta sin aviso. Nuestras transformaciones eran fr√°giles - cualquier campo nuevo o eliminado causaba fallos.
> 
> Lo resolv√≠ implementando detecci√≥n autom√°tica de schema. Cuando llegan datos, mi pipeline infiere el schema y lo compara contra el esperado. Si hay drift, recibo una alerta inmediatamente pero el pipeline no se rompe - maneja el cambio graciosamente. Tambi√©n hice las transformaciones m√°s flexibles usando funciones COALESCE y TRY_CAST.
> 
> ¬øEl resultado? Los fallos de pipeline cayeron en 60%, y cuando los schemas cambian, lo s√© instant√°neamente en lugar de descubrirlo cuando los dashboards se rompen."

---

### ‚òÅÔ∏è Q19. ¬øC√≥mo manejas arquitecturas multi-cloud?

| Capa | GCP | AWS | Abstracci√≥n |
|------|-----|-----|-------------|
| üì¶ **Almacenamiento** | GCS | S3 | Paths unificados |
| ‚ö° **C√≥mputo** | Cloud Functions | Lambda | Mismos patrones de c√≥digo |
| üìä **Anal√≠tica** | BigQuery | Redshift | SQL est√°ndar |
| üéº **Orquestaci√≥n** | Composer | MWAA | DAGs de Airflow |
| üìù **Logging** | Cloud Logging | CloudWatch | Formato unificado |

> üí° **C√≥mo respondo esto:**
> 
> "Manejo multi-cloud creando capas de abstracci√≥n. Para almacenamiento, uso patrones de path unificados - al c√≥digo no le importa si es S3 o GCS. Para c√≥mputo, escribo Cloud Functions y Lambda con los mismos patrones - la l√≥gica es id√©ntica, solo cambian los triggers. Para anal√≠tica, uso SQL est√°ndar que funciona tanto en BigQuery como Redshift. Para orquestaci√≥n, uso Airflow - los mismos DAGs corren en Composer (GCP) o MWAA (AWS) con cambios m√≠nimos. Para logging, uso formato unificado para poder analizar logs de ambos clouds en un solo lugar. Este enfoque me permite mover workloads entre clouds sin reescribir todo."

---

### ü§ñ Q20. ¬øC√≥mo has combinado Data Engineering + Generative AI?

| Integraci√≥n | Descripci√≥n |
|-------------|-------------|
| üîç **Pipelines RAG** | BigQuery/vector stores como backend de retrieval |
| ü§ñ **AI Agents** | Ejecutar workflows de datos autom√°ticamente |
| üìà **Predictivo** | Vertex AI, AutoML para forecasting |
| üí° **Insights** | Insights automatizados de clientes, alineaci√≥n de brand voice |

> üí° **C√≥mo respondo esto:**
> 
> "He estado combinando Data Engineering con Generative AI de varias formas. Primero, pipelines RAG - uso BigQuery y vector stores como backend de retrieval. Mis pipelines de datos preparan e indexan documentos para que la IA pueda recuperar contexto relevante. Segundo, AI Agents - construyo agentes que pueden ejecutar workflows de datos autom√°ticamente, como disparar DAGs de Airflow o consultar BigQuery bas√°ndose en solicitudes en lenguaje natural. Tercero, anal√≠tica predictiva - uso Vertex AI y AutoML para construir modelos de forecasting, con mis pipelines preparando los datos de entrenamiento. Cuarto, insights automatizados - uso LLMs para analizar datos de clientes y generar res√∫menes, siempre asegurando alineaci√≥n con brand voice."

---

## üü£ SECCI√ìN 4 ‚Äî Preguntas Comportamentales (Q21-Q25)

---

### üë®‚Äçüè´ Q21. ¬øC√≥mo mentorizas a ingenieros junior?

| M√©todo | Descripci√≥n |
|--------|-------------|
| üìö **Materiales de Onboarding** | Documentaci√≥n estructurada para nuevos |
| üñ•Ô∏è **Sesiones Pr√°cticas** | Pair programming, live coding |
| üìã **Mejores Pr√°cticas** | Est√°ndares y guidelines definidos |
| üîç **Code Reviews** | Feedback educativo, no solo aprobaci√≥n |

> üí° **C√≥mo respondo esto:**
> 
> "Creo en la mentor√≠a estructurada. Cuando un junior se une, empiezo con documentaci√≥n de onboarding - diagramas de arquitectura, patrones comunes, y 'c√≥mo hacemos las cosas aqu√≠'. Luego hago sesiones pr√°cticas donde hacemos pair programming en tareas reales. No solo arreglo su c√≥digo - explico por qu√© hacemos las cosas de cierta manera.
> 
> Cre√© una gu√≠a de mejores pr√°cticas cubriendo estilo SQL, patrones de Airflow, y manejo de errores. Durante code reviews, me enfoco en ense√±ar, no solo aprobar. Hago preguntas como '¬øQu√© pasa si esto falla?' o '¬øC√≥mo escalar√≠a esto?' Esto los ayuda a pensar como ingenieros senior.
> 
> El resultado es que los juniors se vuelven productivos m√°s r√°pido y desarrollan buenos h√°bitos desde el d√≠a uno."

---

### ü§ù Q22. ¬øC√≥mo manejas la colaboraci√≥n cross-funcional?

| Equipo | Tipo de Colaboraci√≥n |
|--------|---------------------|
| ü§ñ **MLEs** | Integraci√≥n de modelos, feature engineering |
| üß™ **QA** | Estrategias de testing, validaci√≥n de datos |
| üìã **PMs** | Requisitos, priorizaci√≥n |
| üíº **Negocio** | Traducir necesidades a soluciones t√©cnicas |

> üí° **C√≥mo respondo esto:**
> 
> "Trabajo de cerca con diferentes equipos cada d√≠a. Con ML Engineers, colaboro en feature engineering - preparo los datos que necesitan para modelos y ayudo a integrar sus predicciones de vuelta en nuestros pipelines. Con QA, definimos estrategias de testing y reglas de validaci√≥n de datos juntos.
> 
> Con Product Managers, traduzco requisitos de negocio en especificaciones t√©cnicas. Los ayudo a entender qu√© es factible y cu√°nto toman las cosas. Con stakeholders de Negocio, soy el traductor - me dicen qu√© insights necesitan, y yo descubro c√≥mo obtener los datos ah√≠.
> 
> La clave es comunicaci√≥n. Evito jerga t√©cnica con personas no t√©cnicas y me enfoco en resultados: 'Esto te dar√° reportes diarios en lugar de semanales' en vez de 'Implementar√© un patr√≥n ETL incremental.'"

---

### üìö Q23. ¬øC√≥mo te mantienes actualizado?

| M√©todo | Plataforma | Enfoque |
|--------|------------|---------|
| üéì **Cursos** | Google Cloud Skills Boost | Cloud & AI |
| üîß **Open Source** | Contribuciones en GitHub | Habilidades pr√°cticas |
| üì∫ **Ense√±anza** | Streams en vivo en Twitch | Compartir con comunidad |
| üõ†Ô∏è **Proyectos** | Builds personales | Aprendizaje pr√°ctico |

> üí° **C√≥mo respondo esto:**
> 
> "Me mantengo actualizado a trav√©s de m√∫ltiples canales. Tomo cursos en Google Cloud Skills Boost para aprender nuevas features de cloud y AI. Contribuyo a proyectos open source en GitHub - esto me obliga a leer c√≥digo de otras personas y aprender nuevos patrones. Tambi√©n ense√±o en streams en vivo de Twitch - explicar conceptos a otros me ayuda a entenderlos mejor. Finalmente, construyo proyectos personales para experimentar con nuevas tecnolog√≠as antes de usarlas en el trabajo."

---

### üí™ Q24. ¬øCu√°l ha sido el proyecto m√°s desafiante?

| Fase | Descripci√≥n |
|------|-------------|
| üéØ **Proyecto** | Plataforma de marketing analytics en tiempo real |
| üîß **Desaf√≠o** | 5+ APIs con diferentes schemas, rate limits, auth |
| ‚ö†Ô∏è **Problemas** | Consistencia de datos, fallos de API, updates en tiempo real, costos |

| Componente de Soluci√≥n | Implementaci√≥n |
|------------------------|----------------|
| üõ°Ô∏è **Manejo de Errores** | L√≥gica robusta de retry y fallback |
| üìê **Normalizaci√≥n de Schema** | Modelo de datos unificado |
| üìä **Carga Incremental** | Updates eficientes de datos |
| üîî **Monitoreo** | Alertas de anomal√≠as antes del impacto |

> üí° **C√≥mo respondo esto:**
> 
> "Mi proyecto m√°s desafiante fue construir una plataforma de marketing analytics en tiempo real que extra√≠a datos de 5+ APIs - Google Ads, Meta, TikTok, LinkedIn, X. Cada API ten√≠a diferentes schemas, rate limits, y m√©todos de autenticaci√≥n. Los desaf√≠os eran consistencia de datos entre fuentes, manejar fallos de API graciosamente, proveer updates en tiempo real, y controlar costos.
> 
> Lo resolv√≠ implementando manejo robusto de errores con retries y fallbacks, normalizando schemas en un modelo de datos unificado, usando carga incremental para ser eficiente, y configurando monitoreo para detectar anomal√≠as antes de que impactaran reportes. El resultado fue una plataforma confiable de la que los marketers ahora dependen diariamente."

---

### üéØ Q25. ¬øQu√© buscas en un nuevo rol?

| Buscando | Descripci√≥n |
|----------|-------------|
| üöÄ **Desaf√≠o** | Problemas de Data & AI a escala |
| ‚òÅÔ∏è **Tecnolog√≠a** | Arquitecturas cloud-native modernas |
| üë• **Equipo** | Colegas talentosos y colaborativos |
| üìö **Crecimiento** | Aprendizaje y compartir conocimiento |

> üí° **C√≥mo respondo esto:**
> 
> "Busco un rol donde pueda resolver problemas desafiantes de data y AI a escala. Quiero trabajar con arquitecturas cloud-native modernas - no sistemas legacy. Valoro un equipo de colegas talentosos y colaborativos que se empujen mutuamente a crecer. M√°s importante, quiero oportunidades de aprendizaje continuo y una cultura de compartir conocimiento. Me emocionan los roles que combinan Data Engineering tradicional con Generative AI - ah√≠ es donde veo el futuro de nuestro campo."

---

## ‚ö´ SECCI√ìN 5 ‚Äî Experto: Preguntas Senior DE + AI (Q26-Q30)

---

### ü§ñ Q26. ¬øCu√°l es tu enfoque para arquitecturas multi-agente?

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    ARQUITECTURA MULTI-AGENTE                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îÇ
‚îÇ    ‚îÇ Agente A ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ   ROUTER /   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Agente B ‚îÇ              ‚îÇ
‚îÇ    ‚îÇ(Investig)‚îÇ     ‚îÇ  ARBITRADOR  ‚îÇ     ‚îÇ(Escritor)‚îÇ              ‚îÇ
‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îÇ
‚îÇ         ‚îÇ                  ‚îÇ                  ‚îÇ                     ‚îÇ
‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ
‚îÇ                            ‚ñº                                        ‚îÇ
‚îÇ                   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                                  ‚îÇ
‚îÇ                   ‚îÇCAPA MEMORIA  ‚îÇ                                  ‚îÇ
‚îÇ                   ‚îÇ  COMPARTIDA  ‚îÇ                                  ‚îÇ
‚îÇ                   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

| Componente | Prop√≥sito |
|------------|-----------|
| üé≠ **Roles Especializados** | Cada agente tiene responsabilidad distinta |
| üîß **Interacciones Tool** | Agentes usan tools para acciones |
| üß† **Memoria Compartida** | Persistencia de estado entre agentes |
| üîÄ **L√≥gica de Routing** | Dirigir queries al agente correcto |

> üí° **C√≥mo respondo esto:**
> 
> "Dise√±o sistemas multi-agente con roles especializados. Cada agente tiene una responsabilidad - por ejemplo, Agente A investiga, Agente B escribe. Un router o arbitrador decide qu√© agente maneja cada query. Todos los agentes comparten una capa de memoria para tener contexto sobre la conversaci√≥n. Uso tools para que los agentes tomen acciones - b√∫squeda, consultar bases de datos, llamar APIs. La clave es separaci√≥n clara de concerns y l√≥gica de routing robusta. Implemento esto usando LangGraph, que me permite definir workflows de agentes complejos como m√°quinas de estado."

---

### üìä Q27. ¬øC√≥mo mides la calidad de sistemas RAG o agentes?

| M√©trica | Descripci√≥n | Objetivo |
|---------|-------------|----------|
| üéØ **Precisi√≥n de Retrieval** | Docs relevantes recuperados | > 90% |
| üìù **Relevancia de Contexto** | Contexto coincide con query | > 85% |
| üö´ **Tasa de Alucinaci√≥n** | Informaci√≥n falsa | < 5% |
| üîÑ **Consistencia Multi-turno** | Conversaciones coherentes | > 95% |
| üé§ **Alineaci√≥n Brand Voice** | Coincide con tono de marca | Revisi√≥n manual |
| üîß **√âxito de Ejecuci√≥n de Tools** | Tools funcionan correctamente | > 99% |
| ‚è±Ô∏è **Latencia de Respuesta** | Tiempo para responder | < 2s |

> üí° **C√≥mo respondo esto:**
> 
> "Mido calidad de RAG y agentes con m√©tricas espec√≠ficas. Precisi√≥n de retrieval - ¬øestamos recuperando documentos relevantes? Objetivo >90%. Relevancia de contexto - ¬øel contexto coincide con el query? Objetivo >85%. Tasa de alucinaci√≥n - ¬øla IA est√° inventando cosas? Objetivo <5%. Consistencia multi-turno - ¬ølas conversaciones son coherentes entre turnos? Objetivo >95%. Para ejecuci√≥n de tools, espero >99% tasa de √©xito. Latencia de respuesta debe ser <2s. Alineaci√≥n de brand voice requiere revisi√≥n manual - muestreo respuestas semanalmente para asegurar que coincidan con nuestro tono. Ejecuto tests de regresi√≥n antes de cada deployment para capturar regresiones de calidad."

---

### üîí Q28. ¬øC√≥mo manejas gobernanza de datos y compliance?

| √Årea | Implementaci√≥n |
|------|----------------|
| üìä **Lineage** | Rastrear origen de datos y transformaciones |
| üîê **Seguridad** | Enmascarado a nivel columna, encriptaci√≥n |
| üë§ **Control de Acceso** | IAM con privilegio m√≠nimo |
| üìù **Documentaci√≥n** | Ownership de datos, pol√≠ticas de retenci√≥n |
| üõ°Ô∏è **Compliance** | Detecci√≥n automatizada de datos personales sensibles (emails, tel√©fonos, IDs) |

> üí° **C√≥mo respondo esto:**
> 
> "La gobernanza de datos est√° integrada en mis pipelines desde el d√≠a uno. Implemento rastreo de lineage para saber de d√≥nde viene cada pieza de datos y c√≥mo se transforma. Para seguridad, uso enmascarado a nivel columna para campos sensibles y encriptaci√≥n en reposo y en tr√°nsito. El control de acceso sigue privilegio m√≠nimo - los usuarios solo ven lo que necesitan. Documento ownership de datos y pol√≠ticas de retenci√≥n para cada dataset. Para compliance, ejecuto escaneos automatizados para detectar datos personales sensibles como emails, n√∫meros de tel√©fono e IDs - si algo aparece donde no deber√≠a, recibo una alerta inmediatamente."

---

### üí∞ Q29. ¬øC√≥mo abordas la optimizaci√≥n de costos?

| Estrategia | Implementaci√≥n | Ahorros |
|------------|----------------|---------|
| üìÖ **Particionado** | Query solo datos necesarios | 50-80% |
| üóÑÔ∏è **Pol√≠ticas Lifecycle** | Hot ‚Üí Cold ‚Üí Archive | 40-70% |
| üìä **Right-sizing** | Ajustar c√≥mputo a workload | 20-40% |
| üíµ **Spot Instances** | Usar preemptible para batch | 60-90% |
| üîî **Alertas de Costo** | Monitorear anomal√≠as | Preventivo |

> üí° **C√≥mo respondo esto:**
> 
> "La optimizaci√≥n de costos es un proceso continuo. Particionado es la mayor ganancia - al particionar tablas por fecha, los queries escanean solo particiones relevantes, ahorrando 50-80% en costos de query. Implemento pol√≠ticas de lifecycle para mover datos de hot (SSD) a cold (HDD) a archive (Glacier/Coldline), ahorrando 40-70%. Hago right-sizing de c√≥mputo - si un job corre bien en n1-standard-4, no uso n1-standard-16. Para jobs batch, uso instancias spot/preemptible que cuestan 60-90% menos. Finalmente, configuro alertas de costo para capturar anomal√≠as antes de que se conviertan en facturas grandes. Estas pr√°cticas han ahorrado miles de d√≥lares mensualmente."

---

### üèóÔ∏è Q30. ¬øCu√°l es tu experiencia con data mesh?

| Principio | Implementaci√≥n |
|-----------|----------------|
| üè¢ **Ownership de Dominio** | Equipos son due√±os de sus productos de datos |
| üì¶ **Data as Product** | M√©tricas de calidad, documentaci√≥n, SLAs |
| üõ†Ô∏è **Plataforma Self-Serve** | Equipos publican/consumen independientemente |
| üèõÔ∏è **Gobernanza Federada** | Est√°ndares con autonom√≠a |

> üí° **C√≥mo respondo esto:**
> 
> "He implementado principios de data mesh en organizaciones transicionando de equipos de datos centralizados. La clave es ownership de dominio - cada equipo es due√±o de sus productos de datos, no un equipo central. Ayudo a los equipos a tratar los datos como producto con m√©tricas de calidad, documentaci√≥n y SLAs. Construyo plataformas self-serve donde los equipos pueden publicar y consumir datos independientemente. La gobernanza es federada - definimos est√°ndares a nivel compa√±√≠a (naming, seguridad), pero los equipos tienen autonom√≠a en implementaci√≥n. El resultado es entrega de datos m√°s r√°pida porque los equipos no esperan por un equipo central, mientras mantienen calidad y consistencia."

---

# üéØ SECCI√ìN 5.1 ‚Äî Portafolio de Proyectos Clave

> **Prop√≥sito:** Proyectos reales para referenciar en entrevistas.

---

## üìä Resumen de Proyectos

| # | Proyecto | Cloud | Categor√≠a | Resultado Clave |
|---|----------|-------|-----------|-----------------|
| 1Ô∏è‚É£ | **CDP (Customer Data Platform)** | üîµ GCP | Plataforma de Datos | 5M+ perfiles unificados, 25% reducci√≥n CAC |
| 1Ô∏è‚É£B | **CDP (Customer Data Platform)** | üü† AWS | Plataforma de Datos | 50M+ eventos/d√≠a, compliance de seguridad y privacidad |
| 2Ô∏è‚É£ | **Sistema de Alertas Tiempo Real** | üîµ GCP | Monitoreo | < 5 min latencia de alerta, 40% ahorro de costos |
| 2Ô∏è‚É£B | **Sistema de Alertas Tiempo Real** | üü† AWS | Monitoreo | < 5 min latencia de alerta, 40% ahorro de costos |
| 3Ô∏è‚É£ | **Sistema de Insights Multi-Modal** | üîµ GCP | AI/Analytics | 70% menos revisi√≥n manual, 18% mejora ROAS |
| 3Ô∏è‚É£B | **Sistema de Insights Multi-Modal** | üü† AWS | AI/Analytics | 70% menos revisi√≥n manual, 18% mejora ROAS |
| 4Ô∏è‚É£ | **Framework de Gobernanza** | üîµ GCP | Gobernanza | 65% menos incidentes, 30% ahorro de costos |
| 4Ô∏è‚É£B | **Framework de Gobernanza** | üü† AWS | Gobernanza | 65% menos incidentes, 30% ahorro de costos |
| 5Ô∏è‚É£ | **Arquitectura de Pipelines AI-Driven** | üîµ GCP | Arquitectura | 80% desarrollo de features m√°s r√°pido |
| 5Ô∏è‚É£B | **Arquitectura de Pipelines AI-Driven** | üü† AWS | Arquitectura | 80% desarrollo de features m√°s r√°pido |
| 6Ô∏è‚É£ | **Agentes de Marketing Analyst AI** | üîµ GCP | GenAI | Insights automatizados, an√°lisis manual reducido |
| 6Ô∏è‚É£B | **Agentes de Marketing Analyst AI** | üü† AWS | GenAI | Insights automatizados, an√°lisis manual reducido |
| 7Ô∏è‚É£ | **Sistemas RAG & Multi-Agente** | üîµ GCP | GenAI | B√∫squeda grounded, workflows inteligentes |
| 7Ô∏è‚É£B | **Sistemas RAG & Multi-Agente** | üü† AWS | GenAI | B√∫squeda grounded, workflows inteligentes |
| 8Ô∏è‚É£ | **Sistemas de Alertas y Predictivos** | üîµ GCP | ML/Monitoreo | Alertas proactivas, anal√≠tica predictiva |
| 8Ô∏è‚É£B | **Sistemas de Alertas y Predictivos** | üü† AWS | ML/Monitoreo | Alertas proactivas, anal√≠tica predictiva |
| 9Ô∏è‚É£ | **Arquitectura de Datos AI-Native** | üîµ GCP | Arquitectura | Infraestructura lista para ML |
| 9Ô∏è‚É£B | **Arquitectura de Datos AI-Native** | üü† AWS | Arquitectura | Infraestructura lista para ML |

---

## üéØ Proyecto 1: Customer Data Platform (CDP) ‚Äî GCP

### üìã Resumen

| Aspecto | Detalles |
|---------|----------|
| üî¥ **Problema** | Datos de clientes fragmentados en 8+ sistemas |
| üéØ **Objetivo** | Vista unificada para personalizaci√≥n, reducir CAC |
| ‚òÅÔ∏è **Cloud** | Google Cloud Platform |

### üí¨ Mi Experiencia (C√≥mo lo explicar√≠a en una entrevista)

> *"En este proyecto, fui responsable de construir una Customer Data Platform desde cero. El equipo de marketing ten√≠a datos de clientes dispersos en 8 sistemas diferentes ‚Äî CRM, analytics del sitio web, eventos de app m√≥vil, plataformas de ads como Google Ads y Meta, e incluso logs de call center. Nadie ten√≠a una vista unificada del cliente.*
>
> *Empec√© extrayendo datos de Supermetrics y las diferentes APIs de plataformas de ads usando **BigQuery Data Transfers** ‚Äî este es un servicio nativo de GCP que autom√°ticamente programa y carga datos desde fuentes como Google Ads, Google Analytics, y conectores de terceros como Supermetrics directamente a BigQuery. Para eventos en tiempo real del sitio web y app m√≥vil, configur√© Pub/Sub para capturar todo a medida que suced√≠a. Luego us√© Dataproc con Spark Structured Streaming para procesar los datos de streaming y realizar identity resolution ‚Äî b√°sicamente emparejando usuarios entre sistemas usando email, n√∫meros de tel√©fono y device IDs.*
>
> *Todos los datos procesados llegaron a BigQuery, que particion√© por fecha y clusteriz√© por customer_id para rendimiento √≥ptimo de queries. Constru√≠ la capa de transformaci√≥n con Dataform, creando un modelo de datos limpio con capas staging, intermediate y mart. Todo el pipeline fue orquestado con Cloud Composer ejecutando refreshes diarios.*
>
> *Para activaci√≥n, conect√© los perfiles unificados a Vertex AI para construir modelos de propensi√≥n ‚Äî prediciendo qu√© clientes era probable que convirtieran. Estas predicciones se retroalimentaron a Google Ads y Meta para targeting de audiencias. El resultado final fue 5 millones de perfiles unificados y una reducci√≥n del 25% en costo de adquisici√≥n de clientes."*

### üèóÔ∏è Arquitectura

```
FUENTES DE DATOS ‚Üí INGESTA ‚Üí PROCESAMIENTO ‚Üí ALMACENAMIENTO ‚Üí ACTIVACI√ìN
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[CRM]          BQ Data Transfers  Dataproc      BigQuery     Vertex AI
[Website]  ‚îÄ‚îÄ‚ñ∫ Pub/Sub        ‚îÄ‚îÄ‚ñ∫ (Spark)   ‚îÄ‚îÄ‚ñ∫ GCS      ‚îÄ‚îÄ‚ñ∫ Looker
[Mobile]       Cloud Functions    Dataform                   Ad APIs
[Ads]
[Call Center]
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ Cloud Composer (Airflow) Orquestaci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üîß Implementaci√≥n T√©cnica

| Capa | Componentes | Detalles |
|------|-------------|----------|
| üì• **Ingesta** | BigQuery Data Transfers, Pub/Sub | Supermetrics/ads v√≠a Data Transfers, tiempo real v√≠a Pub/Sub |
| ‚öôÔ∏è **Procesamiento** | Dataproc (Spark), Dataform | Identity resolution, transformaciones |
| üíæ **Almacenamiento** | BigQuery, GCS | Particionado por fecha, clusterizado por customer_id |
| üîó **Identidad** | Matching personalizado | Email, tel√©fono, device IDs |
| üéØ **Activaci√≥n** | Vertex AI, APIs | Modelos de propensi√≥n, sync de audiencias |
| üéº **Orquestaci√≥n** | Cloud Composer | Refreshes diarios, reentrenamiento ML |

### üìà Resultados

| M√©trica | Resultado |
|---------|-----------|
| üë• **Perfiles Unificados** | 5M+ de 8 fuentes de datos |
| üí∞ **Reducci√≥n CAC** | 25% mejora |
| ‚ö° **Procesamiento de Eventos** | 10K eventos/segundo |
| ‚è±Ô∏è **Latencia** | Vista 360¬∞ en < 15 minutos |

---

## üéØ Proyecto 1B: Customer Data Platform (CDP) ‚Äî AWS

### üìã Resumen

| Aspecto | Detalles |
|---------|----------|
| üî¥ **Problema** | Misma necesidad de negocio, infraestructura AWS |
| üéØ **Objetivo** | Vista unificada del cliente, compliance-first |
| ‚òÅÔ∏è **Cloud** | Amazon Web Services |

### üí¨ Mi Experiencia (C√≥mo lo explicar√≠a en una entrevista)

> *"En este proyecto, fui responsable de construir una Customer Data Platform desde cero en AWS. El equipo de marketing ten√≠a datos de clientes dispersos en 8 sistemas diferentes ‚Äî CRM, analytics del sitio web, eventos de app m√≥vil, plataformas de ads como Google Ads y Meta, e incluso logs de call center. Nadie ten√≠a una vista unificada del cliente.*
>
> *A diferencia de GCP que tiene BigQuery Data Transfers como servicio nativo, AWS no tiene un equivalente directo para fuentes de datos de marketing. As√≠ que para extraer datos de Supermetrics y APIs de plataformas de ads, us√© **Fivetran** (una herramienta ELT de terceros) que conecta con 150+ fuentes y carga datos directamente en S3 y Redshift. Alternativamente, para algunas fuentes us√© **AWS AppFlow** para integraciones SaaS como Salesforce y Google Analytics, y **funciones Lambda** disparadas por EventBridge para extracciones de APIs personalizadas donde Fivetran/AppFlow no ten√≠an conectores. Para eventos en tiempo real del sitio web y app m√≥vil, configur√© Kinesis Data Streams para capturar todo a medida que suced√≠a, y configur√© Kinesis Firehose para entregar autom√°ticamente los datos a S3 en formato Parquet. Luego us√© AWS Glue con Spark para procesar los datos y realizar identity resolution ‚Äî b√°sicamente emparejando usuarios entre sistemas usando email, n√∫meros de tel√©fono y device IDs.*
>
> *Todos los datos procesados llegaron a S3 organizado como data lake con capas Bronze, Silver y Gold ‚Äî datos raw en Bronze, datos limpios en Silver, y agregaciones listas para negocio en Gold. Para la capa de warehouse, us√© Redshift Serverless que particion√© por fecha y us√© distribution keys en customer_id para rendimiento √≥ptimo de queries. Tambi√©n configur√© Redshift Spectrum para consultar el data lake de S3 directamente sin mover datos.*
>
> *La capa de transformaci√≥n fue construida con scripts SQL personalizados y jobs de Glue, creando un modelo de datos limpio con capas staging, intermediate y mart. Todo el pipeline fue orquestado con MWAA (Managed Airflow) ejecutando refreshes diarios.*
>
> *Para activaci√≥n, conect√© los perfiles unificados a SageMaker para construir modelos de propensi√≥n ‚Äî prediciendo qu√© clientes era probable que convirtieran. Estas predicciones se retroalimentaron a Google Ads y Meta para targeting de audiencias. Lake Formation manej√≥ todo el control de acceso ‚Äî pod√≠a controlar qui√©n ve qu√© datos a nivel columna, como ocultar direcciones de email de ciertos equipos. El resultado final fue m√°s de 50 millones de eventos procesados diariamente y el mismo impacto de negocio: perfiles de clientes unificados y costos de adquisici√≥n reducidos."*

### üèóÔ∏è Arquitectura

```
FUENTES DE DATOS ‚Üí INGESTA ‚Üí PROCESAMIENTO ‚Üí ALMACENAMIENTO ‚Üí ACTIVACI√ìN
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
[CRM]          Fivetran/AppFlow   Glue/EMR      Redshift    SageMaker
[Website]  ‚îÄ‚îÄ‚ñ∫ Kinesis        ‚îÄ‚îÄ‚ñ∫ Step      ‚îÄ‚îÄ‚ñ∫ S3 Lake ‚îÄ‚îÄ‚ñ∫ QuickSight
[Mobile]       Lambda             Functions                  Ad APIs
[Ads]          EventBridge
[Call Center]
               ‚îî‚îÄ‚îÄ‚îÄ‚îÄ MWAA (Managed Airflow) Orquestaci√≥n ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### üü† Patrones Espec√≠ficos de AWS

| Patr√≥n | Servicio | Prop√≥sito |
|--------|----------|-----------|
| üì• **Ingesta de Datos** | Fivetran / AppFlow / Lambda | Sin Data Transfers nativo como GCP |
| üì§ Auto-delivery | Kinesis Firehose | Entrega a S3 + transformaci√≥n |
| üîí Gobernanza | Lake Formation | Control de acceso centralizado |
| üîç Queries ad-hoc | Athena | Query S3 directamente |
| üîó S3 desde Redshift | Redshift Spectrum | Tablas externas |

> üí° **GCP vs AWS Ingesta de Datos:**
> 
> | Aspecto | üîµ GCP | üü† AWS |
> |---------|--------|--------|
> | **Servicio Nativo** | BigQuery Data Transfers | ‚ùå Sin equivalente directo |
> | **Datos de Marketing** | Conector Supermetrics | Fivetran, Stitch, Airbyte |
> | **Fuentes SaaS** | Data Transfers | AWS AppFlow (fuentes limitadas) |
> | **APIs Personalizadas** | Cloud Functions | Lambda + EventBridge |
> 
> *"AWS no tiene un servicio de Data Transfer nativo como GCP. Para fuentes de datos de marketing como Supermetrics, Google Ads y Meta, uso herramientas ELT de terceros como Fivetran o Airbyte. Para fuentes SaaS como Salesforce, AWS AppFlow funciona bien. Para APIs personalizadas sin conectores, construyo funciones Lambda disparadas por EventBridge en un schedule."*

### üìà Resultados

| M√©trica | Resultado |
|---------|-----------|
| ‚ö° **Eventos/D√≠a** | 50M+ con latencia sub-segundo |
| üí∞ **Modelo de Costos** | Redshift Serverless (pago por query) |
| üîó **Data Sharing** | AWS Data Exchange |
| üîí **Compliance** | Auditor√≠as de seguridad + leyes de privacidad v√≠a Lake Formation |

---

## üí° C√≥mo Presentar Proyectos en Entrevistas

### üåü Usa el M√©todo STAR

| Letra | Significado | Enfoque |
|-------|-------------|---------|
| **S** | Situaci√≥n | Problema de negocio |
| **T** | Tarea | Tu responsabilidad |
| **A** | Acci√≥n | Decisiones t√©cnicas |
| **R** | Resultado | Impacto cuantificado |

### üìù Ejemplo de Respuesta

> *"En mi proyecto CDP, la **situaci√≥n** era que marketing ten√≠a datos de clientes fragmentados en 8 sistemas. Mi **tarea** fue dise√±ar una plataforma de datos unificada. **Arquitect√©** una soluci√≥n usando BigQuery para almacenamiento, Dataproc con Spark para identity resolution en streaming, y Vertex AI para modelos de propensi√≥n. El **resultado** fue 5M+ perfiles unificados y una reducci√≥n del 25% en costo de adquisici√≥n de clientes."*

---

# ‚ùì SECCI√ìN 6 ‚Äî Preguntas para Hacer al Entrevistador

---

## üìã Resumen de Preguntas

| # | Pregunta | Prop√≥sito |
|---|----------|-----------|
| 1Ô∏è‚É£ | D√≠a t√≠pico | Entender balance de trabajo |
| 2Ô∏è‚É£ | Mayores desaf√≠os | Insight de madurez de datos |
| 3Ô∏è‚É£ | Enfoque de calidad de datos | Madurez de pr√°cticas |
| 4Ô∏è‚É£ | Stack tecnol√≥gico | Herramientas y evoluci√≥n |
| 5Ô∏è‚É£ | M√©tricas de √©xito | Claridad de expectativas |
| 6Ô∏è‚É£ | Oportunidades de aprendizaje | Potencial de crecimiento |
| 7Ô∏è‚É£ | Colaboraci√≥n ML/AI | Integraci√≥n de equipos |
| 8Ô∏è‚É£ | Proceso CI/CD | Madurez de ingenier√≠a |
| 9Ô∏è‚É£ | Onboarding | Nivel de organizaci√≥n |
| üîü | Por qu√© est√° abierta la posici√≥n | Entender contexto |

---

### 1Ô∏è‚É£ ¬øC√≥mo es un d√≠a t√≠pico para este rol?

| Buscar | Banderas Rojas |
|--------|----------------|
| ‚úÖ Estructura clara | ‚ùå "Cada d√≠a es diferente" |
| ‚úÖ Tiempo para trabajo profundo | ‚ùå Exceso de reuniones |
| ‚úÖ On-call definido | ‚ùå Firefighting constante |

---

### 2Ô∏è‚É£ ¬øCu√°les son los mayores desaf√≠os de datos?

| Buenas Se√±ales | Banderas Rojas |
|----------------|----------------|
| ‚úÖ Desaf√≠os espec√≠ficos | ‚ùå Respuestas vagas |
| ‚úÖ Planes para abordarlos | ‚ùå Negaci√≥n de problemas |
| ‚úÖ Enfoque en escala/calidad | ‚ùå Lista abrumadora sin abordar |

---

### 3Ô∏è‚É£ ¬øC√≥mo aborda el equipo la calidad de datos?

| Buscar | Banderas Rojas |
|--------|----------------|
| ‚úÖ Testing automatizado | ‚ùå "Estamos trabajando en eso" (sin plan) |
| ‚úÖ Data contracts | ‚ùå "Los analistas manejan eso" |
| ‚úÖ Ownership claro | ‚ùå Sin awareness de compliance |

---

### 4Ô∏è‚É£ ¬øCu√°l es el stack tecnol√≥gico?

| Buenas Se√±ales | Banderas Rojas |
|----------------|----------------|
| ‚úÖ Stack moderno | ‚ùå Desactualizado sin planes de upgrade |
| ‚úÖ Disposici√≥n a evolucionar | ‚ùå Churn constante |
| ‚úÖ Presupuesto para herramientas | ‚ùå Sin estabilidad |

---

### 5Ô∏è‚É£ ¬øC√≥mo miden el √©xito?

| Buenas Se√±ales | Banderas Rojas |
|----------------|----------------|
| ‚úÖ OKRs/KPIs claros | ‚ùå "Solo mantener las cosas funcionando" |
| ‚úÖ M√©tricas de uptime de pipeline | ‚ùå Sin m√©tricas claras |
| ‚úÖ Objetivos de freshness de datos | ‚ùå Puramente subjetivo |

---

### 6Ô∏è‚É£ ¬øQu√© oportunidades de aprendizaje y crecimiento hay?

| Buenas Se√±ales | Banderas Rojas |
|----------------|----------------|
| ‚úÖ Presupuesto de training | ‚ùå "Estamos muy ocupados" |
| ‚úÖ Asistencia a conferencias | ‚ùå Sin career ladder |
| ‚úÖ Ejemplos de promoci√≥n | ‚ùå Sin mentor√≠a |

---

### 7Ô∏è‚É£ ¬øC√≥mo colabora el equipo con equipos de ML/AI?

| Buenas Se√±ales | Banderas Rojas |
|----------------|----------------|
| ‚úÖ Infraestructura compartida | ‚ùå Equipos en silos |
| ‚úÖ Feature stores | ‚ùå "Ellos hacen lo suyo" |
| ‚úÖ Pr√°cticas MLOps | ‚ùå Fricci√≥n entre equipos |

---

### 8Ô∏è‚É£ ¬øC√≥mo es el proceso de CI/CD?

| Buenas Se√±ales | Banderas Rojas |
|----------------|----------------|
| ‚úÖ CI/CD automatizado | ‚ùå Deployments manuales |
| ‚úÖ Deployments frecuentes | ‚ùå Sin testing |
| ‚úÖ Infrastructure as code | ‚ùå "Deploy cuando est√© listo" |

---

### 9Ô∏è‚É£ ¬øC√≥mo es el onboarding?

| Buenas Se√±ales | Banderas Rojas |
|----------------|----------------|
| ‚úÖ Plan 30/60/90 d√≠as | ‚ùå "Ya lo descubrir√°s" |
| ‚úÖ Buddy/mentor asignado | ‚ùå Sin documentaci√≥n |
| ‚úÖ Documentaci√≥n de calidad | ‚ùå Nadar o hundirse |

---

### üîü ¬øPor qu√© est√° abierta esta posici√≥n?

| Buenas Se√±ales | Banderas Rojas |
|----------------|----------------|
| ‚úÖ Expansi√≥n del equipo | ‚ùå Alta rotaci√≥n |
| ‚úÖ Nueva iniciativa | ‚ùå Respuestas vagas |
| ‚úÖ Proyectos de crecimiento | ‚ùå Persona anterior "se fue de repente" |

---

## üí° Tips Pro para Hacer Preguntas

| Tip | Por qu√© |
|-----|---------|
| üéØ **Elegir 3-4 preguntas** | No abrumar; ajustar al flujo de conversaci√≥n |
| üìù **Tomar notas** | Muestra seriedad; ayuda a comparar ofertas |
| üîç **Hacer follow-ups** | "¬øPuedes dar un ejemplo?" profundiza respuestas |
| üë• **Adaptar al entrevistador** | Preguntas t√©cnicas para ingenieros, cultura para managers |
| üí∞ **Guardar salario para HR** | Evitar en rondas tempranas |

---

